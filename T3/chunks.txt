[
  {
    "chunk_id": "chunk_1",
    "content": "Licensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nINTERNATIONAL \nSTANDARD\n\nISO/IEC \n42001\n\nFirst edition \n2023-12\n\nInformation technology — Artificial \nintelligence — Management system\n\nTechnologies de l'information — Intelligence artificielle — Système \nde management\n\nPlease share your feedback about \nthe standard. Scan the QR code \nwith your phone or click the link\n\nCustomer Feedback Form\n\nReference number \nISO/IEC 42001:2023(E)\n\n© ISO/IEC 2023\n\n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nCOPYRIGHT PROTECTED DOCUMENT"
  },
  {
    "chunk_id": "chunk_2",
    "content": "COPYRIGHT PROTECTED DOCUMENT\n\n©  ISO/IEC 2023\nAll rights reserved. Unless otherwise specified, or required in the context of its implementation, no part of this publication may \nbe reproduced or utilized otherwise in any form or by any means, electronic or mechanical, including photocopying, or posting on \nthe internet or an intranet, without prior written permission. Permission can be requested from either ISO at the address below \nor ISO’s member body in the country of the requester.\n\nISO copyright office\nCP 401 • Ch. de Blandonnet 8\nCH-1214 Vernier, Geneva\nPhone: +41 22 749 01 11\nEmail: copyright@iso.org\nWebsite: www.iso.org\n\nPublished in Switzerland\n\nii\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nContents \n\nForeword\n\nPage\nv\n\nIntroduction"
  },
  {
    "chunk_id": "chunk_3",
    "content": "ISO/IEC 42001:2023(E)\n\nContents \n\nForeword\n\nPage\nv\n\nIntroduction\n\n ..........................................................................................................................................................................................................................................\n\nvi\n\n1 \n\n2 \n\n3 \n\n4 \n\n5 \n\n6 \n\n7 \n\n8 \n\n9 \n\nScope\n\n ..............................................................................................................................................................................................................................\n\nNormative references\n\n .................................................................................................................................................................................................................................\n\nTerms and definitions"
  },
  {
    "chunk_id": "chunk_4",
    "content": "Terms and definitions\n\n .....................................................................................................................................................................................\n\nContext of the organization\n\n ....................................................................................................................................................................................\n\n1\n\n1\n\n1\n\n5\n\n ......................................................................................................................................................................\n\n4.1 \n4.2 \n4.3 \nLeadership\n4.4"
  },
  {
    "chunk_id": "chunk_5",
    "content": "4.1 \n4.2 \n4.3 \nLeadership\n4.4 \n\nUnderstanding the organization and its context ..................................................................................................... 5\nUnderstanding the needs and expectations of interested parties ........................................................... 6\nDetermining the scope of the AI management system ....................................................................................... 6\n7\nAI management system ................................................................................................................................................................... 6\n\n ..................................................................................................................................................................................................................\n\n5.1 \n5.2 \nPlanning\n5.3 \n\n6.1 \n\n6.2 \nSupport\n6.3 \n\n7.1 \n7.2 \n7.3 \n7.4 \n7.5 \n\nOperation"
  },
  {
    "chunk_id": "chunk_6",
    "content": "Leadership and commitment ..................................................................................................................................................... 7\nAI policy ........................................................................................................................................................................................................ 7\n8\nRoles, responsibilities and authorities .............................................................................................................................. 8\n ........................................................................................................................................................................................................................\nActions to address risks and opportunities ................................................................................................................. 8"
  },
  {
    "chunk_id": "chunk_7",
    "content": "Actions to address risks and opportunities ................................................................................................................. 8\n6.1.1  General ........................................................................................................................................................................................ 8\n6.1.2  AI risk assessment ............................................................................................................................................................ 9\n6.1.3  AI risk treatment ................................................................................................................................................................ 9\n6.1.4  AI system impact assessment .............................................................................................................................. 10"
  },
  {
    "chunk_id": "chunk_8",
    "content": "6.1.4  AI system impact assessment .............................................................................................................................. 10\nAI objectives and planning to achieve them .............................................................................................................. 10\n11\nPlanning of changes ........................................................................................................................................................................ 11\n ........................................................................................................................................................................................................................\nResources ................................................................................................................................................................................................. 11"
  },
  {
    "chunk_id": "chunk_9",
    "content": "Competence ............................................................................................................................................................................................ 11\nAwareness ................................................................................................................................................................................................ 12\nCommunication ................................................................................................................................................................................... 12\nDocumented information ........................................................................................................................................................... 12\n7.5.1  General ..................................................................................................................................................................................... 12"
  },
  {
    "chunk_id": "chunk_10",
    "content": "7.5.1  General ..................................................................................................................................................................................... 12\n7.5.2  Creating and updating documented information .............................................................................. 12\n13\n7.5.3  Control of documented information .............................................................................................................. 13\n ..................................................................................................................................................................................................................\nOperational planning and control ...................................................................................................................................... 13"
  },
  {
    "chunk_id": "chunk_11",
    "content": "Operational planning and control ...................................................................................................................................... 13\nAI risk assessment ............................................................................................................................................................................ 13\nAI risk treatment ............................................................................................................................................................................... 14\n14\nAI system impact assessment ................................................................................................................................................ 14"
  },
  {
    "chunk_id": "chunk_12",
    "content": "8.1 \n8.2 \n8.3 \nPerformance evaluation\n8.4 \n\n ..........................................................................................................................................................................."
  },
  {
    "chunk_id": "chunk_13",
    "content": "9.1  Monitoring, measurement, analysis and evaluation .......................................................................................... 14\nInternal audit ........................................................................................................................................................................................ 14\n9.2 \n9.2.1  General ..................................................................................................................................................................................... 14\nInternal audit programme ...................................................................................................................................... 14\n9.2.2 \n9.3  Management review ....................................................................................................................................................................... 15"
  },
  {
    "chunk_id": "chunk_14",
    "content": "9.3  Management review ....................................................................................................................................................................... 15\n9.3.1  General ..................................................................................................................................................................................... 15\n9.3.2  Management review inputs ................................................................................................................................... 15\n15\n9.3.3  Management review results .................................................................................................................................. 15"
  },
  {
    "chunk_id": "chunk_15",
    "content": "Improvement\n\n .........................................................................................................................................................................................................\n\n10 \n\nAnnex A \n\n10.1  Continual improvement ............................................................................................................................................................... 15\n17\n10.2  Nonconformity and corrective action ............................................................................................................................. 16\n\n  Reference control objectives and controls\n\n(normative)\n\n .....................................................................................\n\n© ISO/IEC 2023 – All rights reserved \n\niii\n\n \n\fISO/IEC 42001:2023(E)"
  },
  {
    "chunk_id": "chunk_16",
    "content": "(normative)\n\n .....................................................................................\n\n© ISO/IEC 2023 – All rights reserved \n\niii\n\n \n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nAnnex B \n\nAnnex C \n\n  Implementation guidance for AI controls\n\n21\n\n(normative)\n\n  Potential AI-related organizational objectives and risk sources\n\n .......................................................................................\n\n46\n\nAnnex D \n\n(informative)\n\n  Use of the AI management system across domains or sectors\n\n .......................\n\nBibliography\n\n(informative)\n\n .............................\n\n49\n\n51"
  },
  {
    "chunk_id": "chunk_17",
    "content": "46\n\nAnnex D \n\n(informative)\n\n  Use of the AI management system across domains or sectors\n\n .......................\n\nBibliography\n\n(informative)\n\n .............................\n\n49\n\n51\n\n .............................................................................................................................................................................................................................\n\niv\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nForeword"
  },
  {
    "chunk_id": "chunk_18",
    "content": "ISO/IEC 42001:2023(E)\n\nForeword\n\nISO  (the  International  Organization  for  Standardization)  and  IEC  (the  International  Electrotechnical \nCommission)  form  the  specialized  system  for  worldwide  standardization.  National  bodies  that  are \nmembers  of  ISO  or  IEC  participate  in  the  development  of  International  Standards  through  technical \ncommittees  established  by  the  respective  organization  to  deal  with  particular  fields  of  technical \nactivity. ISO and IEC technical committees collaborate in fields of mutual interest. Other international \norganizations, governmental and non-governmental, in liaison with ISO and IEC, also take part in the \nwork."
  },
  {
    "chunk_id": "chunk_19",
    "content": "The  procedures  used  to  develop  this  document  and  those  intended  for  its  further  maintenance \nare  described  in  the  ISO/IEC  Directives,  Part  1.  In  particular,  the  different  approval  criteria \nneeded  for  the  different  types  of  document  should  be  noted.  This  document  was  drafted  in \naccordance  with  the  editorial  rules  of  the  ISO/IEC  Directives,  Part  2  (see  www.iso.org/directives  or \nwww.iec.ch/members_experts/refdocs)."
  },
  {
    "chunk_id": "chunk_20",
    "content": "ISO and IEC draw attention to the possibility that the implementation of this document may involve the \nuse of (a) patent(s). ISO and IEC take no position concerning the evidence, validity or applicability of \nany claimed patent rights in respect thereof. As of the date of publication of this document, ISO and IEC \nhad not received notice of (a) patent(s) which may be required to implement this document. However, \nimplementers are cautioned that this may not represent the latest information, which may be obtained \nfrom the patent database available at www.iso.org/patents and https://patents.iec.ch. ISO and IEC shall \nnot be held responsible for identifying any or all such patent rights.\n\nAny trade name used in this document is information given for the convenience of users and does not \nconstitute an endorsement."
  },
  {
    "chunk_id": "chunk_21",
    "content": "Any trade name used in this document is information given for the convenience of users and does not \nconstitute an endorsement.\n\nFor  an  explanation  of  the  voluntary  nature  of  standards,  the  meaning  of  ISO  specific  terms  and \nexpressions  related  to  conformity  assessment,  as  well  as  information  about  ISO's  adherence  to \nthe  World  Trade  Organization  (WTO)  principles  in  the  Technical  Barriers  to  Trade  (TBT)  see \nInformation  technology\nwww.iso.org/iso/foreword.html. In the IEC, see www.iec.ch/understanding-standards.\n\nArtificial intelligence\n\nThis  document  was  prepared  by  Joint  Technical  Committee  ISO/IEC  JTC  1, \nSubcommittee SC 42, \n\n.\n\n, \n\nAny  feedback  or  questions  on  this  document  should  be  directed  to  the  user’s  national  standards \nbody.  A  complete  listing  of  these  bodies  can  be  found  at  www.iso.org/members.html  and \nwww.iec.ch/national-committees.\n\n© ISO/IEC 2023 – All rights reserved \n\nv"
  },
  {
    "chunk_id": "chunk_22",
    "content": "© ISO/IEC 2023 – All rights reserved \n\nv\n\n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nIntroduction\n\nArtificial  intelligence  (AI)  is  increasingly  applied  across  all  sectors  utilizing  information  technology \nand  is  expected  to  be  one  of  the  main  economic  drivers.  A  consequence  of  this  trend  is  that  certain \napplications can give rise to societal challenges over the coming years.\n\nThis document intends to help organizations responsibly perform their role with respect to AI systems \n(e.g.  to  use,  develop,  monitor  or  provide  products  or  services  that  utilize  AI).  AI  potentially  raises \nspecific considerations such as:\n\n—  The use of AI for automatic decision-making, sometimes in a non-transparent and non-explainable"
  },
  {
    "chunk_id": "chunk_23",
    "content": "—  The use of AI for automatic decision-making, sometimes in a non-transparent and non-explainable \n\nway, can require specific management beyond the management of classical IT systems.\n\n—  The use of data analysis, insight and machine learning, rather than human-coded logic to design \nsystems, both increases the application opportunities for AI systems and changes the way that such \nsystems are developed, justified and deployed.\n\n—  AI  systems  that  perform  continuous  learning  change  their  behaviour  during  use.  They  require \n\nspecial consideration to ensure their responsible use continues with changing behaviour."
  },
  {
    "chunk_id": "chunk_24",
    "content": "—  AI  systems  that  perform  continuous  learning  change  their  behaviour  during  use.  They  require \n\nspecial consideration to ensure their responsible use continues with changing behaviour.\n\nThis  document  provides  requirements  for  establishing,  implementing,  maintaining  and  continually \nimproving an AI management system within the context of an organization. Organizations are expected \nto focus their application of requirements on features that are unique to AI. Certain features of AI, such \nas the ability to continuously learn and improve or a lack of transparency or explainability, can warrant \ndifferent safeguards if they raise additional concerns compared to how the task would traditionally be \nperformed. The adoption of an AI management system to extend the existing management structures is \na strategic decision for an organization."
  },
  {
    "chunk_id": "chunk_25",
    "content": "The organization’s needs and objectives, processes, size and structure as well  as the expectations of \nvarious  interested  parties  influence  the  establishment  and  implementation  of  the  AI  management \nsystem.  Another  set  of  factors  that  influence  the  establishment  and  implementation  of  the  AI \nmanagement  system  are  the  many  use  cases  for  AI  and  the  need  to  strike  the  appropriate  balance \nbetween governance mechanisms and innovation. Organizations can elect to apply these requirements \nusing a risk-based approach to ensure that the appropriate level of control is applied for the particular \nAI  use  cases,  services  or  products  within  the  organization’s  scope.  All  these  influencing  factors  are \nexpected to change and be reviewed from time to time."
  },
  {
    "chunk_id": "chunk_26",
    "content": "The  AI  management  system  should  be  integrated  with  the  organization’s  processes  and  overall \nmanagement structure. Specific issues related to AI should be considered in the design of processes, \ninformation systems and controls. Crucial examples of such management processes are:\n\n—  determination  of  organizational  objectives,  involvement  of  interested  parties  and  organizational \n\npolicy;\n\n—  management of risks and opportunities;\n\n—  processes  for  the  management  of  concerns  related  to  the  trustworthiness  of  AI  systems  such  as \nsecurity, safety, fairness, transparency, data quality and quality of AI systems throughout their life \ncycle;\n\n—  processes for the management of suppliers, partners and third parties that provide or develop AI \n\nsystems for the organization.\n\nThis document provides guidelines for the deployment of applicable controls to support such processes."
  },
  {
    "chunk_id": "chunk_27",
    "content": "systems for the organization.\n\nThis document provides guidelines for the deployment of applicable controls to support such processes.\n\nThis  document  avoids  specific  guidance  on  management  processes.  The  organization  can  combine \ngenerally  accepted  frameworks,  other  International  Standards  and  its  own  experience  to  implement \ncrucial processes such as risk management, life cycle management and data quality management which \nare appropriate for the specific AI use cases, products or services within the scope.\n\nvi\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nAn  organization  conforming  with  the  requirements  in  this  document  can  generate  evidence  of  its \nresponsibility and accountability regarding its role with respect to AI systems."
  },
  {
    "chunk_id": "chunk_28",
    "content": "An  organization  conforming  with  the  requirements  in  this  document  can  generate  evidence  of  its \nresponsibility and accountability regarding its role with respect to AI systems.\n\nThe order in which requirements are presented in this document does not reflect their importance or \nimply the order in which they are implemented. The list items are enumerated for reference purposes \nCompatibility with other management system standards\nonly.\n\nThis  document  applies  the  harmonized  structure  (identical  clause  numbers,  clause  titles,  text  and \ncommon  terms  and  core  definitions)  developed  to  enhance  alignment  among  management  system \nstandards (MSS). The AI management system provides requirements specific to managing the issues \nand risks arising from using AI in an organization. This common approach facilitates implementation \nand consistency with other management system standards, e.g. related to quality, safety, security and \nprivacy."
  },
  {
    "chunk_id": "chunk_29",
    "content": "© ISO/IEC 2023 – All rights reserved \n\nvii\n\n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nINTERNATIONAL STANDARD\n\nISO/IEC 42001:2023(E)\n\nInformation technology — Artificial intelligence — \nManagement system\n\n1  Scope\n\nThis  document  specifies  the  requirements  and  provides  guidance  for  establishing,  implementing, \nmaintaining  and  continually  improving  an  AI  (artificial  intelligence)  management  system  within  the \ncontext of an organization."
  },
  {
    "chunk_id": "chunk_30",
    "content": "This  document  is  intended  for  use  by  an  organization  providing  or  using  products  or  services  that \nutilize  AI  systems.  This  document  is  intended  to  help  the  organization  develop,  provide  or  use  AI \nsystems responsibly in pursuing its objectives and meet applicable requirements, obligations related to \ninterested parties and expectations from them.\n\nThis document is applicable to any organization, regardless of size, type and nature, that provides or \nuses products or services that utilize AI systems.\n2  Normative references"
  },
  {
    "chunk_id": "chunk_31",
    "content": "This document is applicable to any organization, regardless of size, type and nature, that provides or \nuses products or services that utilize AI systems.\n2  Normative references\n\nThe  following  documents  are  referred  to  in  the  text  in  such  a  way  that  some  or  all  of  their  content \nconstitutes  requirements  of  this  document.  For  dated  references,  only  the  edition  cited  applies.  For \nInformation  technology  —  Artificial  intelligence  —  Artificial  intelligence  concepts \nundated references, the latest edition of the referenced document (including any amendments) applies.\nand terminology\nISO/IEC  22989:2022, \n\n3  Terms and definitions\n\nFor the purposes of this document, the terms and definitions given in ISO/IEC 22989 and the following \napply.\n\nISO and IEC maintain terminology databases for use in standardization at the following addresses:\n\n—  ISO Online browsing platform: available at https:// www .iso .org/ obp"
  },
  {
    "chunk_id": "chunk_32",
    "content": "ISO and IEC maintain terminology databases for use in standardization at the following addresses:\n\n—  ISO Online browsing platform: available at https:// www .iso .org/ obp\n\n3.1\n—  IEC Electropedia: available at https:// www .electropedia .org/ \norganization\n\nobjectives\n\nperson or group of people that has its own functions with responsibilities, authorities and relationships \nto achieve its \n\n (3.6)\n\nNote 1 to entry: The concept of organization includes, but is not limited to, sole-trader, company, corporation, firm, \nenterprise, authority, partnership, charity or institution or part or combination thereof, whether incorporated or \nnot, public or private.\n\nmanagement system\nNote 2 to entry: If the organization is part of a larger entity, the term “organization” refers only to the part of the \n3.2\nlarger entity that is within the scope of the AI \ninterested party\n\n (3.4).\n\norganization\n\nperson or \nor activity"
  },
  {
    "chunk_id": "chunk_33",
    "content": "(3.4).\n\norganization\n\nperson or \nor activity\n\n (3.1) that can affect, be affected by, or perceive itself to be affected by a decision \n\nNote 1 to entry: An overview of interested parties in AI is provided in ISO/IEC 22989:2022, 5.19.\n\n1\n\n© ISO/IEC 2023 – All rights reserved \n\n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\n3.3\ntop management\n\norganization\n\nperson or group of people who directs and controls an \n\n (3.1) at the highest level\n\nNote  1  to  entry:  Top  management  has  the  power  to  delegate  authority  and  provide  resources  within  the \norganization.\n\nmanagement  system\n\nNote  2  to  entry:  If  the  scope  of  the \n3.4\nmanagement refers to those who direct and control that part of the organization.\nmanagement system\n\n  (3.4)  covers  only  part  of  an  organization,  then  top \n\norganization"
  },
  {
    "chunk_id": "chunk_34",
    "content": "(3.4)  covers  only  part  of  an  organization,  then  top \n\norganization\n\npolicies\n\nobjectives\nset  of  interrelated  or  interacting  elements  of  an \n\nprocesses\n\n  (3.1)  to  establish \n\n  (3.5)  and \n\n (3.6), as well as \n\n (3.8) to achieve those objectives\n\nNote 1 to entry: A management system can address a single discipline or several disciplines.\n\nNote 2 to entry: The management system elements include the organization’s structure, roles and responsibilities, \n3.5\nplanning and operation.\npolicy\n\norganization\n\ntop management\n\n3.6\nintentions and direction of an \nobjective\n\nresult to be achieved\n\n (3.1) as formally expressed by its \n\n (3.3)\n\nNote 1 to entry: An objective can be strategic, tactical, or operational.\n\nprocess\n\nNote 2 to entry: Objectives can relate to different disciplines (such as finance, health and safety, and environment). \nThey can be, for example, organization-wide or specific to a project, product or \n\n (3.8)."
  },
  {
    "chunk_id": "chunk_35",
    "content": "(3.8).\n\nNote  3  to  entry:  An  objective  can  be  expressed  in  other  ways,  e.g.  as  an  intended  result,  as  a  purpose,  as  an \noperational  criterion,  as  an  AI  objective  or  by  the  use  of  other  words  with  similar  meaning  (e.g.  aim,  goal,  or \ntarget).\n\nmanagement systems\n\norganization\n\npolicy\n\nNote 4 to entry: In the context of AI \n3.7\nconsistent with the AI \nrisk\n\n (3.5), to achieve specific results.\n\n (3.4), AI objectives are set by the \n\n (3.1), \n\neffect of uncertainty\n\nNote 1 to entry: An effect is a deviation from the expected — positive or negative.\n\nNote 2 to entry: Uncertainty is the state, even partial, of deficiency of information related to, understanding or \nknowledge of, an event, its consequence, or likelihood.\n\nNote  3  to  entry:  Risk  is  often  characterized  by  reference  to  potential  events  (as  defined  in  ISO  Guide  73)  and \nconsequences (as defined in ISO Guide 73), or a combination of these."
  },
  {
    "chunk_id": "chunk_36",
    "content": "Note  4  to  entry:  Risk  is  often  expressed  in  terms  of  a  combination  of  the  consequences  of  an  event  (including \n3.8\nchanges in circumstances) and the associated likelihood (as defined in ISO Guide 73) of occurrence.\nprocess\n\nset of interrelated or interacting activities that uses or transforms inputs to deliver a result\n\nNote 1 to entry: Whether the result of a process is called an output, a product or a service depends on the context \nof the reference.\n\n2\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\n3.9\ncompetence\n\n3.10\nability to apply knowledge and skills to achieve intended results\ndocumented information\n\norganization\n\ninformation  required  to  be  controlled  and  maintained  by  an \nwhich it is contained\n\n  (3.1)  and  the  medium  on"
  },
  {
    "chunk_id": "chunk_37",
    "content": "organization\n\ninformation  required  to  be  controlled  and  maintained  by  an \nwhich it is contained\n\n  (3.1)  and  the  medium  on \n\nNote 1 to entry: Documented information can be in any format and media and from any source.\n\nNote 2 to entry: Documented information can refer to:\n\nmanagement system\n\nprocesses\n\n— \n\nthe \n\n (3.4), including related \n\n (3.8);\n\n— \n\ninformation created in order for the organization to operate (documentation);\n\n3.11\n—  evidence of results achieved (records).\nperformance\n\nmeasurable result\n\nNote 1 to entry: Performance can relate either to quantitative or qualitative findings.\norganizations\nNote 2 to entry: Performance can relate to managing activities, \n\nprocesses\n\n (3.8), products, services, systems or \n\n (3.1).\n\nmanagement system"
  },
  {
    "chunk_id": "chunk_38",
    "content": "processes\n\n (3.8), products, services, systems or \n\n (3.1).\n\nmanagement system\n\nNote 3 to entry: In the context of this document, performance refers both to results achieved by using AI systems \n (3.4). The correct interpretation of the term is clear from the \nand results related to the AI \n3.12\ncontext of its use.\ncontinual improvement\n\nperformance\n\n3.13\nrecurring activity to enhance \neffectiveness\n\n (3.11)\n\n3.14\nextent to which planned activities are realized and planned results are achieved\nrequirement\n\nneed or expectation that is stated, generally implied or obligatory\ninterested parties\nNote 1 to entry: “Generally implied” means that it is custom or common practice for the \n\norganization\n\n (3.1) and \n\n (3.2) that the need or expectation under consideration is implied.\n\ndocumented information\n\n3.15\nNote 2 to entry: A specified requirement is one that is stated, e.g. in \nconformity\n\n (3.10).\n\nrequirement\n\n3.16\nfulfilment of a \nnonconformity\n\n (3.14)\n\nrequirement"
  },
  {
    "chunk_id": "chunk_39",
    "content": "documented information\n\n3.15\nNote 2 to entry: A specified requirement is one that is stated, e.g. in \nconformity\n\n (3.10).\n\nrequirement\n\n3.16\nfulfilment of a \nnonconformity\n\n (3.14)\n\nrequirement\n\n3.17\nnon-fulfilment of a \ncorrective action\n\n (3.14)\n\nnonconformity\n\naction to eliminate the cause(s) of a \n\n (3.16) and to prevent recurrence\n\n© ISO/IEC 2023 – All rights reserved \n\n3\n\n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\n3.18\naudit\n\nprocess\n\nsystematic  and  independent \ndetermine the extent to which the audit criteria are fulfilled\n\n  (3.8)  for  obtaining  evidence  and  evaluating  it  objectively  to \n\nNote 1 to entry: An audit can be an internal audit (first party) or an external audit (second party or third party), \nand it can be a combined audit (combining two or more disciplines).\n\norganization"
  },
  {
    "chunk_id": "chunk_40",
    "content": "organization\n\nNote  2  to  entry:  An  internal  audit  is  conducted  by  the \nbehalf.\n\n  (3.1)  itself,  or  by  an  external  party  on  its \n\n3.19\nNote 3 to entry: “Audit evidence” and “audit criteria” are defined in ISO 19011.\nmeasurement\nprocess\n\n3.20\nmonitoring\n\n (3.8) to determine a value\n\nprocess\n\ndetermining the status of a system, a \n\n (3.8) or an activity\n\n3.21\nNote 1 to entry: To determine the status, there can be a need to check, supervise or critically observe.\ncontrol\n\nrisk\n\n<risk> measure that maintains and/or modifies \n\n (3.7)\n\nNote 1 to entry: Controls include, but are not limited to, any process, policy, device, practice or other conditions \nand/or actions which maintain and/or modify risk.\n\nNote 2 to entry: Controls may not always exert the intended or assumed modifying effect.\n\n3.22\n[SOURCE: ISO 31000:2018, 3.8, modified — Added <risk> as application domain ]\ngoverning body"
  },
  {
    "chunk_id": "chunk_41",
    "content": "Note 2 to entry: Controls may not always exert the intended or assumed modifying effect.\n\n3.22\n[SOURCE: ISO 31000:2018, 3.8, modified — Added <risk> as application domain ]\ngoverning body\n\nperson or group of people who are accountable for the performance and conformance of the organization\n\nNote 1 to entry: Not all organizations, particularly small organizations, will have a governing body separate from \ntop management.\n\nNote 2 to entry: A governing body can include, but is not limited to, board of directors, committees of the board, \nsupervisory board, trustees or overseers.\n\n3.23\n[SOURCE: ISO/IEC 38500:2015, 2.9, modified — Added Notes to entry.]\ninformation security\n\npreservation of confidentiality, integrity and availability of information\n\nNote 1 to entry: Other properties such as authenticity, accountability, non-repudiation and reliability can also be \ninvolved.\n\n3.24\n[SOURCE: ISO/IEC 27000:2018, 3.28]\nAI system impact assessment"
  },
  {
    "chunk_id": "chunk_42",
    "content": "Note 1 to entry: Other properties such as authenticity, accountability, non-repudiation and reliability can also be \ninvolved.\n\n3.24\n[SOURCE: ISO/IEC 27000:2018, 3.28]\nAI system impact assessment\n\nformal, documented process by which the impacts on individuals, groups of individuals, or both, and \nsocieties  are  identified,  evaluated  and  addressed  by  an  organization  developing,  providing  or  using \nproducts or services utilizing artificial intelligence\n\n4\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\n3.25\ndata quality\n\ncharacteristic of data that the data meet the organization’s data requirements for a specific context\n\n3.26\n[SOURCE: ISO/IEC 5259-1:—\nstatement of applicability\n\n1)\n\n, 3.4]\n\ncontrols\n\ndocumentation of all necessary"
  },
  {
    "chunk_id": "chunk_43",
    "content": "3.26\n[SOURCE: ISO/IEC 5259-1:—\nstatement of applicability\n\n1)\n\n, 3.4]\n\ncontrols\n\ndocumentation of all necessary \n\n (3.23) and justification for inclusion or exclusion of controls\n\nNote  1  to  entry:  Organizations  may  not  require  all  controls  listed  in  Annex  A  or  may  even  exceed  the  list  in \nAnnex A with additional controls established by the organization itself.\n\nNote 2 to entry: All identified risks shall be documented by the organization according to the requirements of \nthis  document.  All  identified  risks  and  the  risk  management  measures  (controls)  established  to  address  them \nshall be reflected in the statement of applicability.\n4  Context of the organization\n\n4.1  Understanding the organization and its context\n\nThe organization shall determine external and internal issues that are relevant to its purpose and that \naffect its ability to achieve the intended result(s) of its AI management system."
  },
  {
    "chunk_id": "chunk_44",
    "content": "The organization shall determine external and internal issues that are relevant to its purpose and that \naffect its ability to achieve the intended result(s) of its AI management system.\n\nThe organization shall determine whether climate change is a relevant issue.\n\nThe organization shall consider the intended purpose of the AI systems that are developed, provided or \nused by the organization. The organization shall determine its roles with respect to these AI systems.\n\nNOTE 1 \nrole relative to the AI system. These roles can include, but are not limited to, one or more of the following:\n\nTo understand the organization and its context, it can be helpful for the organization to determine its \n\n—  AI providers, including AI platform providers, AI product or service providers;"
  },
  {
    "chunk_id": "chunk_45",
    "content": "To understand the organization and its context, it can be helpful for the organization to determine its \n\n—  AI providers, including AI platform providers, AI product or service providers;\n\n—  AI producers, including AI developers, AI designers, AI operators, AI testers and evaluators, AI deployers, AI \nhuman factor professionals, domain experts, AI impact assessors, procurers, AI governance and oversight \nprofessionals;\n\n—  AI customers, including AI users;\n\n—  AI partners, including AI system integrators and data providers;\n\n—  AI subjects, including data subjects and other subjects;\n\n—  relevant authorities, including policymakers and regulators."
  },
  {
    "chunk_id": "chunk_46",
    "content": "—  AI partners, including AI system integrators and data providers;\n\n—  AI subjects, including data subjects and other subjects;\n\n—  relevant authorities, including policymakers and regulators.\n\nA  detailed  description  of  these  roles  is  provided  by  ISO/IEC  22989.  Furthermore,  the  types  of  roles  and  their \nrelationship to the AI system life cycle are also described in the NIST AI risk management framework.\n The \norganization’s roles can determine the applicability and extent of applicability of the requirements and controls \nin this document.\n\n[29]\n\nExternal and internal issues to be addressed under this clause can vary according to the organization’s \nNOTE 2 \nroles and jurisdiction and their impact on its ability to achieve the intended outcome(s) of its AI management \nsystem. These can include, but are not limited to:\n\na)  external context related considerations such as:\n\n1)  applicable legal requirements, including prohibited uses of AI;"
  },
  {
    "chunk_id": "chunk_47",
    "content": "a)  external context related considerations such as:\n\n1)  applicable legal requirements, including prohibited uses of AI;\n\n2)  policies,  guidelines  and  decisions  from  regulators  that  have  an  impact  on  the  interpretation  or \n\nenforcement of legal requirements in the development and use of AI systems;\n\n1) \n\n Under preparation. Stage at the time of publication ISO/IEC DIS 5259-1:2023.\n\n5\n\n© ISO/IEC 2023 – All rights reserved \n\n \n \n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\n3) \n\nincentives or consequences associated with the intended purpose and the use of AI systems;\n\n4)  culture, traditions, values, norms and ethics with respect to development and use of AI;\n\n5)  competitive landscape and trends for new products and services using AI systems;\n\nb) \n\ninternal context related considerations such as:"
  },
  {
    "chunk_id": "chunk_48",
    "content": "5)  competitive landscape and trends for new products and services using AI systems;\n\nb) \n\ninternal context related considerations such as:\n\n1)  organizational context, governance, objectives (see 6.2), policies and procedures;\n\n2)  contractual obligations;\n\n3) \n\nintended purpose of the AI system to be developed or used.\n\nNOTE 3 \nRole  determination  can  be  formed  by  obligations  related  to  categories  of  data  the  organization \nprocesses  (e.g.  personally  identifiable  information  (PII)  processor  or  PII  controller  when  processing  PII).  See \nISO/IEC 29100 for PII and related roles. Roles can also be informed by legal requirements specific to AI systems.\n4.2  Understanding the needs and expectations of interested parties\n\nThe organization shall determine:\n\n—  the interested parties that are relevant to the AI management system;\n\n—  the relevant requirements of these interested parties;"
  },
  {
    "chunk_id": "chunk_49",
    "content": "The organization shall determine:\n\n—  the interested parties that are relevant to the AI management system;\n\n—  the relevant requirements of these interested parties;\n\n—  which of these requirements will be addressed through the AI management system.\n\nNOTE  Relevant interested parties can have requirements related to climate change.\n4.3  Determining the scope of the AI management system\n\nThe  organization  shall  determine  the  boundaries  and  applicability  of  the  AI  management  system  to \nestablish its scope.\n\nWhen determining this scope, the organization shall consider:\n\n—  the external and internal issues referred to in 4.1;\n\n—  the requirements referred to in 4.2.\n\nThe scope shall be available as documented information."
  },
  {
    "chunk_id": "chunk_50",
    "content": "—  the external and internal issues referred to in 4.1;\n\n—  the requirements referred to in 4.2.\n\nThe scope shall be available as documented information.\n\nThe scope of the AI management system shall determine the organization’s activities with respect to \nthis document’s requirements on the AI management system, leadership, planning, support, operation, \nperformance, evaluation, improvement, controls and objectives.\n4.4  AI management system\n\nThe  organization  shall  establish,  implement,  maintain,  continually  improve  and  document  an  AI \nmanagement  system,  including  the  processes  needed  and  their  interactions,  in  accordance  with  the \nrequirements of this document.\n\n6\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\n5  Leadership"
  },
  {
    "chunk_id": "chunk_51",
    "content": "ISO/IEC 42001:2023(E)\n\n5  Leadership\n\n5.1  Leadership and commitment\n\nTop management  shall  demonstrate leadership and commitment  with respect  to the AI management \nsystem by:\n\n—  ensuring that the AI policy (see 5.2) and AI objectives (see 6.2) are established and are compatible \n\nwith the strategic direction of the organization;\n\n—  ensuring  the  integration  of  the  AI  management  system  requirements  into  the  organization’s \n\nbusiness processes;\n\n—  ensuring that the resources needed for the AI management system are available;\n\n—  communicating the importance of effective AI management and of conforming to the AI management \n\nsystem requirements;\n\n—  ensuring that the AI management system achieves its intended result(s);\n\n—  directing and supporting persons to contribute to the effectiveness of the AI management system;\n\n—  promoting continual improvement;\n\n—  supporting  other  relevant  roles  to  demonstrate  their  leadership  as  it  applies  to  their  areas  of"
  },
  {
    "chunk_id": "chunk_52",
    "content": "—  promoting continual improvement;\n\n—  supporting  other  relevant  roles  to  demonstrate  their  leadership  as  it  applies  to  their  areas  of \n\nresponsibility.\n\nNOTE 1 \ncore to the purposes of the organization’s existence.\n\nReference to “business” in this document can be interpreted broadly to mean those activities that are \n\nNOTE 2 \nEstablishing,  encouraging  and  modelling  a  culture  within  the  organization,  to  take  a  responsible \napproach to using, development and governing AI systems can be an important demonstration of commitment \nand leadership by top management. Ensuring awareness of and compliance with such a responsible approach and \nin support of the AI management system through leadership can aid the success of the AI management system.\n5.2  AI policy\n\nTop management shall establish an AI policy that:\n\na) \n\nis appropriate to the purpose of the organization;\n\nb)  provides a framework for setting AI objectives (see 6.2);\n\nc)"
  },
  {
    "chunk_id": "chunk_53",
    "content": "Top management shall establish an AI policy that:\n\na) \n\nis appropriate to the purpose of the organization;\n\nb)  provides a framework for setting AI objectives (see 6.2);\n\nc) \n\nincludes a commitment to meet applicable requirements;\n\nd) \n\nincludes a commitment to continual improvement of the AI management system.\n\nThe AI policy shall:\n\n—  be available as documented information;\n\n—  refer as relevant to other organizational policies;\n\n—  be communicated within the organization;\n\n—  be available to interested parties, as appropriate.\n\nControl  objectives  and  controls  for  establishing  an  AI  policy  are  provided  in  A.2  in  Table  A.1. \nImplementation guidance for these controls is provided in B.2.\n\nNOTE \n\nConsiderations for organizations when developing AI policies are provided in ISO/IEC 38507.\n\n© ISO/IEC 2023 – All rights reserved \n\n7\n\n \n \n\fISO/IEC 42001:2023(E)"
  },
  {
    "chunk_id": "chunk_54",
    "content": "NOTE \n\nConsiderations for organizations when developing AI policies are provided in ISO/IEC 38507.\n\n© ISO/IEC 2023 – All rights reserved \n\n7\n\n \n \n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\n5.3  Roles, responsibilities and authorities\n\nTop management shall ensure that the responsibilities and authorities for relevant roles are assigned \nand communicated within the organization.\n\nTop management shall assign the responsibility and authority for:\n\na)  ensuring that the AI management system conforms to the requirements of this document;\n\nb)  reporting on the performance of the AI management system to top management.\n\nA  control  for  defining  and  allocating  roles  and  responsibilities  is  provided  in  A.3.2  in  Table  A.1. \n\nNOTE \nImplementation guidance for this control is provided in B.3.2.\n6  Planning"
  },
  {
    "chunk_id": "chunk_55",
    "content": "A  control  for  defining  and  allocating  roles  and  responsibilities  is  provided  in  A.3.2  in  Table  A.1. \n\nNOTE \nImplementation guidance for this control is provided in B.3.2.\n6  Planning\n\n6.1  Actions to address risks and opportunities\n\n6.1.1  General\n\nWhen planning for the AI management system, the organization shall consider the issues referred to in \n4.1 and the requirements referred to in 4.2 and determine the risks and opportunities that need to be \naddressed to:\n\n—  give assurance that the AI management system can achieve its intended result(s);\n\n—  prevent or reduce undesired effects;\n\n—  achieve continual improvement.\n\nThe organization shall establish and maintain AI risk criteria that support:\n\n—  distinguishing acceptable from non-acceptable risks;\n\n—  performing AI risk assessments;\n\n—  conducting AI risk treatment;\n\n—  assessing AI risk impacts.\n\nNOTE 1 \nretain are provided in ISO/IEC 38507 and ISO/IEC 23894."
  },
  {
    "chunk_id": "chunk_56",
    "content": "—  performing AI risk assessments;\n\n—  conducting AI risk treatment;\n\n—  assessing AI risk impacts.\n\nNOTE 1 \nretain are provided in ISO/IEC 38507 and ISO/IEC 23894.\n\nConsiderations to determine the amount and type of risk that an organization is willing to pursue or \n\nThe organization shall determine the risks and opportunities according to:\n\n—  the domain and application context of an AI system;\n\n—  the intended use;\n\n—  the external and internal context described in 4.1.\n\nNOTE 2  More than one AI system can be considered in the scope of the AI management system. In this case the \ndetermination of opportunities and uses is performed for each AI system or groupings of AI systems.\n\nThe organization shall plan:\n\na)  actions to address these risks and opportunities;\n\nb)  how to:\n\n1) \n\nintegrate and implement the actions into its AI management system processes;\n\n8\n\n2)  evaluate the effectiveness of these actions.\n\n© ISO/IEC 2023 – All rights reserved"
  },
  {
    "chunk_id": "chunk_57",
    "content": "b)  how to:\n\n1) \n\nintegrate and implement the actions into its AI management system processes;\n\n8\n\n2)  evaluate the effectiveness of these actions.\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nThe organization shall retain documented information on actions taken to identify and address AI risks \nand AI opportunities.\n\n.\nGuidance on how to implement risk management for organizations developing, providing or using AI \n\nNOTE 3 \nproducts, systems and services is provided in ISO/IEC 23894\n\nNOTE 4 \nmanagement activities.\n\nThe  context  of  the  organization  and  its  activities  can  have  an  impact  on  the  organization’s  risk"
  },
  {
    "chunk_id": "chunk_58",
    "content": "NOTE 4 \nmanagement activities.\n\nThe  context  of  the  organization  and  its  activities  can  have  an  impact  on  the  organization’s  risk \n\nNOTE 5 \nThe way of defining risk and therefore of envisioning risk management can vary across sectors and \nindustries. The definition of risk in 3.7 allows a broad vision of risk adaptable to any sector, such as the sectors \nmentioned in Annex D. In any case, it is the role of the organization, as part of risk assessment, to first adopt a \nvision of risk adapted to its context. This can include approaching risk through definitions used in sectors where \nthe AI system is developed for and used, such as the definition from ISO/IEC Guide 51.\n6.1.2  AI risk assessment\n\nThe organization shall define and establish an AI risk assessment process that:\n\na) \n\nis informed by and aligned with the AI policy (see 5.2) and AI objectives (see 6.2);\n\nNOTE \nimpact assessment as indicated in 6.1.4."
  },
  {
    "chunk_id": "chunk_59",
    "content": "a) \n\nis informed by and aligned with the AI policy (see 5.2) and AI objectives (see 6.2);\n\nNOTE \nimpact assessment as indicated in 6.1.4.\n\nWhen assessing the consequences as part of 6.1.2 d) 1), the organization can utilize an AI system \n\nb) \n\nis designed such that repeated AI risk assessments can produce consistent, valid and comparable \nresults;\n\nc) \n\nidentifies risks that aid or prevent achieving its AI objectives;\n\nd)  analyses the AI risks to:\n\n1)  assess  the  potential  consequences  to  the  organization,  individuals  and  societies  that  would \n\nresult if the identified risks were to materialize;\n\n2)  assess, where applicable, the realistic likelihood of the identified risks;\n\n3)  determine the levels of risk;\n\ne)  evaluates the AI risks to:\n\n1)  compare the results of the risk analysis with the risk criteria (see 6.1.1);\n\n2)  prioritize the assessed risks for risk treatment."
  },
  {
    "chunk_id": "chunk_60",
    "content": "e)  evaluates the AI risks to:\n\n1)  compare the results of the risk analysis with the risk criteria (see 6.1.1);\n\n2)  prioritize the assessed risks for risk treatment.\n\nThe organization shall retain documented information about the AI risk assessment process.\n6.1.3  AI risk treatment\n\nTaking  the  risk  assessment  results  into  account,  the  organization  shall  define  an  AI  risk  treatment \nprocess to:\n\na)  select appropriate AI risk treatment options;\n\nb)  determine all controls that are necessary to implement the AI risk treatment options chosen and \ncompare the controls with those in Annex A to verify that no necessary controls have been omitted;\n\nNOTE 1 \nrelated to the design and use of AI systems.\n\nAnnex A provides reference controls for meeting organizational objectives and addressing risks \n\nc)  consider the controls from Annex A that are relevant for the implementation of the AI risk treatment \n\noptions;\n\nd)"
  },
  {
    "chunk_id": "chunk_61",
    "content": "c)  consider the controls from Annex A that are relevant for the implementation of the AI risk treatment \n\noptions;\n\nd) \n\nidentify if additional controls are necessary beyond those in Annex A in order to implement all risk \ntreatment options;\n9\n\n© ISO/IEC 2023 – All rights reserved \n\n \n \n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\ne)  consider the guidance in Annex B for the implementation of controls determined in b) and c);"
  },
  {
    "chunk_id": "chunk_62",
    "content": "e)  consider the guidance in Annex B for the implementation of controls determined in b) and c);\n\nControl objectives are implicitly included in the controls chosen. The organization can select an \nNOTE 2 \nappropriate set of control objectives and controls from Annex A. The Annex A controls are not exhaustive \nand additional control objectives and controls can be needed. If different or additional controls are necessary \nbeyond those in Annex A, the organization can design such controls or take them from existing sources. AI \nrisk management can be integrated in other management systems, if applicable."
  },
  {
    "chunk_id": "chunk_63",
    "content": "f)  produce  a  statement  of  applicability  that  contains  the  necessary  controls  [see  b),  c)  and  d)]  and \nprovide justification for inclusion and exclusion of controls. Justification for exclusion can include \nwhere  the  controls  are  not  deemed  necessary  by  the  risk  assessment  and  where  they  are  not \nrequired by (or are subject to exceptions under) applicable external requirements.\n\nNOTE 3 \ngeneral or for specific AI systems, whether those listed in Annex A or established by the organization itself.\n\nThe organization can provide documented justifications for excluding any control objectives in \n\ng) \n\nformulate an AI risk treatment plan.\n\nThe organization shall obtain approval from the designated management for the AI risk treatment plan \nand for acceptance of the residual AI risks. The necessary controls shall be:\n\n—  aligned to the objectives in 6.2;\n\n—  available as documented information;\n\n—  communicated within the organization;"
  },
  {
    "chunk_id": "chunk_64",
    "content": "—  aligned to the objectives in 6.2;\n\n—  available as documented information;\n\n—  communicated within the organization;\n\n—  available to interested parties, as appropriate.\n\nThe organization shall retain documented information about the AI risk treatment process.\n6.1.4  AI system impact assessment\n\nThe  organization  shall  define  a  process  for  assessing  the  potential  consequences  for  individuals  or \ngroups of individuals, or both, and societies that can result from the development, provision or use of AI \nsystems.\n\nThe  AI  system  impact  assessment  shall  determine  the  potential  consequences  an  AI  system’s \ndeployment, intended use and foreseeable misuse has on individuals or groups of individuals, or both, \nand societies.\n\nThe  AI  system  impact  assessment  shall  take  into  account  the  specific  technical  and  societal  context \nwhere the AI system is deployed and applicable jurisdictions."
  },
  {
    "chunk_id": "chunk_65",
    "content": "The  AI  system  impact  assessment  shall  take  into  account  the  specific  technical  and  societal  context \nwhere the AI system is deployed and applicable jurisdictions.\n\nThe result of the AI system impact assessment shall be documented. Where appropriate, the result of \nthe system impact assessment can be made available to relevant interested parties as defined by the \norganization.\n\nThe organization shall consider the results of the AI system impact assessment in the risk assessment \n(see 6.1.2). A.5 in Table A.1 provides controls for assessing impacts of AI systems.\n\nIn  some  contexts  (such  as  safety  or  privacy  critical  AI  systems),  the  organization  can  require  that \nNOTE \ndiscipline-specific AI system impact assessments (e.g. safety, privacy or security impact) be performed as part of \nthe overall risk management activities of an organization.\n6.2  AI objectives and planning to achieve them"
  },
  {
    "chunk_id": "chunk_66",
    "content": "The organization shall establish AI objectives at relevant functions and levels.\n\nThe AI objectives shall:\n\na)  be consistent with the AI policy (see 5.2);\n10\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nb)  be measurable (if practicable);\n\nc) \n\ntake into account applicable requirements;\n\nd)  be monitored;\n\ne)  be communicated;\n\nf)  be updated as appropriate;\n\ng)  be available as documented information.\n\nWhen planning how to achieve its AI objectives, the organization shall determine:\n\n—  what will be done;\n\n—  what resources will be required;\n\n—  who will be responsible;\n\n—  when it will be completed;\n\n—  how the results will be evaluated."
  },
  {
    "chunk_id": "chunk_67",
    "content": "—  what will be done;\n\n—  what resources will be required;\n\n—  who will be responsible;\n\n—  when it will be completed;\n\n—  how the results will be evaluated.\n\nNOTE \nA  non-exclusive  list  of  AI  objectives  relating  to  risk  management  is  provided  in  Annex  C.  Control \nobjectives  and  controls  for  identifying  objectives  for  responsible  development  and  use  of  AI  systems  and \nmeasures  to  achieve  them  are  provided  in  A.6.1  and  A.9.3  in  Table  A.1.  Implementation  guidance  for  these \ncontrols is provided in B.6.1 and B.9.3.\n6.3  Planning of changes\n\nWhen  the  organization  determines  the  need  for  changes  to  the  AI  management  system,  the  changes \nshall be carried out in a planned manner.\n7  Support\n\n7.1  Resources\n\nThe  organization  shall  determine  and  provide  the  resources  needed  for  the  establishment, \nimplementation, maintenance and continual improvement of the AI management system."
  },
  {
    "chunk_id": "chunk_68",
    "content": "The  organization  shall  determine  and  provide  the  resources  needed  for  the  establishment, \nimplementation, maintenance and continual improvement of the AI management system.\n\nControl  objectives  and  controls  for  AI  resources  are  provided  in  A.4  in  Table  A.1.  Implementation \n\nNOTE \nguidance for these controls is provided in Clause B.4.\n7.2  Competence\n\nThe organization shall:\n\n—  determine the necessary competence of person(s) doing work under its control that affects its AI \n\nperformance;\n\n—  ensure  that  these  persons  are  competent  on  the  basis  of  appropriate  education,  training  or \n\nexperience;\n\n—  where applicable, take actions to acquire the necessary competence, and evaluate the effectiveness \n\nof the actions taken.\n\nAppropriate documented information shall be available as evidence of competence.\n\nNOTE 1 \nprovided in B.4.6.\n\nImplementation  guidance  for  human  resources  including  consideration  of  necessary  expertise  is \n\n11"
  },
  {
    "chunk_id": "chunk_69",
    "content": "NOTE 1 \nprovided in B.4.6.\n\nImplementation  guidance  for  human  resources  including  consideration  of  necessary  expertise  is \n\n11\n\n© ISO/IEC 2023 – All rights reserved \n\n \n \n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nApplicable actions can include, for example: the provision of training to, the mentoring of, or the re-\n\nNOTE 2 \nassignment of currently employed persons; or the hiring or contracting of competent persons.\n7.3  Awareness\n\nPersons doing work under the organization’s control shall be aware of:\n\n—  the AI policy (see 5.2);\n\n—  their  contribution  to  the  effectiveness  of  the  AI  management  system,  including  the  benefits  of \n\nimproved AI performance;\n\n—  the implications of not conforming with the AI management system requirements.\n7.4  Communication"
  },
  {
    "chunk_id": "chunk_70",
    "content": "improved AI performance;\n\n—  the implications of not conforming with the AI management system requirements.\n7.4  Communication\n\nThe  organization  shall  determine  the  internal  and  external  communications  relevant  to  the  AI \nmanagement system including:\n\n—  what it will communicate;\n\n—  when to communicate;\n\n—  with whom to communicate;\n\n—  how to communicate.\n7.5  Documented information\n\n7.5.1  General\n\nThe organization’s AI management system shall include:\n\na)  documented information required by this document;\n\nb)  documented information determined by the organization as being necessary for the effectiveness \n\nof the AI management system.\n\nNOTE \nto another due to:\n\nThe extent of documented information for an AI management system can differ from one organization \n\n— \n\nthe size of organization and its type of activities, processes, products and services;\n\n— \n\nthe complexity of processes and their interactions;\n\n— \n7.5.2  Creating and updating documented information"
  },
  {
    "chunk_id": "chunk_71",
    "content": "— \n\nthe complexity of processes and their interactions;\n\n— \n7.5.2  Creating and updating documented information\n\nthe competence of persons.\n\nWhen creating and updating documented information, the organization shall ensure appropriate:\n\n— \n\nidentification and description (e.g. a title, date, author or reference number);\n\n— \n\nformat (e.g. language, software version, graphics) and media (e.g. paper, electronic);\n\n—  review and approval for suitability and adequacy.\n\n12\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\n7.5.3  Control of documented information\n\nDocumented  information  required  by  the  AI  management  system  and  by  this  document  shall  be \ncontrolled to ensure:\n\na) \n\nit is available and suitable for use, where and when it is needed;\n\nb)"
  },
  {
    "chunk_id": "chunk_72",
    "content": "a) \n\nit is available and suitable for use, where and when it is needed;\n\nb) \n\nit is adequately protected (e.g. from loss of confidentiality, improper use or loss of integrity).\n\nFor the control of documented information, the organization shall address the following activities, as \napplicable:\n\n—  distribution, access, retrieval and use;\n\n—  storage and preservation, including preservation of legibility;\n\n—  control of changes (e.g. version control);\n\n—  retention and disposition.\n\nDocumented  information  of  external  origin  determined  by  the  organization  to  be  necessary  for  the \nplanning and operation of the AI management system shall be identified as appropriate and controlled.\n\nAccess can imply a decision regarding the permission to view the documented information only, or \n\nNOTE \nthe permission and authority to view and change the documented information.\n8  Operation\n\n8.1  Operational planning and control"
  },
  {
    "chunk_id": "chunk_73",
    "content": "NOTE \nthe permission and authority to view and change the documented information.\n8  Operation\n\n8.1  Operational planning and control\n\nThe organization shall plan, implement and control the processes needed to meet requirements, and to \nimplement the actions determined in Clause 6, by:\n\n—  establishing criteria for the processes;\n\n— \n\nimplementing control of the processes in accordance with the criteria.\n\nThe  organization  shall  implement  the  controls  determined  according  to  6.1.3  that  are  related  to  the \noperation  of  the  AI  management  system  (e.g.  AI  system  development  and  usage  life  cycle  related \ncontrols).\n\nThe  effectiveness  of  these  controls  shall  be  monitored  and  corrective  actions  shall  be  considered \nif  the  intended  results  are  not  achieved.  Annex  A  lists  reference  controls  and  Annex  B  provides \nimplementation guidance for them."
  },
  {
    "chunk_id": "chunk_74",
    "content": "Documented  information  shall  be  available  to  the  extent  necessary  to  have  confidence  that  the \nprocesses have been carried out as planned.\n\nThe organization shall control planned changes and review the consequences of unintended changes, \ntaking action to mitigate any adverse effects, as necessary.\n\nThe organization shall ensure that externally provided processes, products or services that are relevant \nto the AI management system are controlled.\n8.2  AI risk assessment\n\nThe organization shall  perform AI risk  assessments in accordance with 6.1.2 at  planned intervals or \nwhen significant changes are proposed or occur.\n\nThe organization shall retain documented information of the results of all AI risk assessments.\n\n13\n\n© ISO/IEC 2023 – All rights reserved \n\n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited."
  },
  {
    "chunk_id": "chunk_75",
    "content": "Licensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\n8.3  AI risk treatment\n\nThe  organization  shall  implement  the  AI  risk  treatment  plan  according  to  6.1.3  and  verify  its \neffectiveness.\n\nWhen  risk  assessments  identify  new  risks  that  require  treatment,  a  risk  treatment  process  in \naccordance with 6.1.3 shall be performed for these risks.\n\nWhen risk treatment options as defined by the risk treatment plan are not effective, these treatment \noptions shall be reviewed and revalidated following the risk treatment process according to 6.1.3 and \nthe risk treatment plan shall be updated.\n\nThe organization shall retain documented information of the results of all AI risk treatments.\n8.4  AI system impact assessment"
  },
  {
    "chunk_id": "chunk_76",
    "content": "The organization shall retain documented information of the results of all AI risk treatments.\n8.4  AI system impact assessment\n\nThe organization shall perform AI system impact assessments according to 6.1.4 at planned intervals \nor when significant changes are proposed to occur.\n\nThe  organization  shall  retain  documented  information  of  the  results  of  all  AI  system  impact \nassessments.\n9  Performance evaluation\n\n9.1  Monitoring, measurement, analysis and evaluation\n\nThe organization shall determine:\n\n—  what needs to be monitored and measured;\n\n—  the methods for monitoring, measurement, analysis and evaluation, as applicable, to ensure valid \n\nresults;\n\n—  when the monitoring and measuring shall be performed;\n\n—  when the results from monitoring and measurement shall be analysed and evaluated.\n\nDocumented information shall be available as evidence of the results.\n\nThe organization shall evaluate the performance and the effectiveness of the AI management system.\n9.2"
  },
  {
    "chunk_id": "chunk_77",
    "content": "Documented information shall be available as evidence of the results.\n\nThe organization shall evaluate the performance and the effectiveness of the AI management system.\n9.2 \n\nInternal audit\n\n9.2.1  General\n\nThe organization shall conduct internal audits at planned intervals to provide information on whether \nthe AI management system:\n\na)  conforms to:\n\n1) \n\nthe organization’s own requirements for its AI management system;\n\n2) \n\nthe requirements of this document;\n\nb) \n9.2.2 \n\nis effectively implemented and maintained.\n\nInternal audit programme\n\nThe organization shall plan, establish, implement and maintain (an) audit programme(s), including the \nfrequency, methods, responsibilities, planning requirements and reporting.\n14\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)"
  },
  {
    "chunk_id": "chunk_78",
    "content": "ISO/IEC 42001:2023(E)\n\nWhen establishing the internal audit programme(s), the organization shall consider the importance of \nthe processes concerned and the results of previous audits.\n\nThe organization shall:\n\na)  define the audit objectives, criteria and scope for each audit;\n\nb)  select auditors and conduct audits to ensure objectivity and the impartiality of the audit process;\n\nc)  ensure that the results of audits are reported to relevant managers.\n\nDocumented information shall be available as evidence of the implementation of the audit programme(s) \nand the audit results.\n9.3  Management review\n\n9.3.1  General\n\nTop management shall review the organization’s AI management system, at planned intervals, to ensure \nits continuing suitability, adequacy and effectiveness.\n9.3.2  Management review inputs\n\nThe management review shall include:\n\na) \n\nthe status of actions from previous management reviews;"
  },
  {
    "chunk_id": "chunk_79",
    "content": "The management review shall include:\n\na) \n\nthe status of actions from previous management reviews;\n\nb)  changes in external and internal issues that are relevant to the AI management system;\n\nc)  changes in needs and expectations of interested parties that are relevant to the AI management \n\nsystem;\n\nd) \n\ninformation on the AI management system performance, including trends in:\n\n1)  nonconformities and corrective actions;\n\n2)  monitoring and measurement results;\n\n3)  audit results;\n\ne)  opportunities for continual improvement.\n9.3.3  Management review results\n\nThe  results  of  the  management  review  shall  include  decisions  related  to  continual  improvement \nopportunities and any need for changes to the AI management system.\n\nDocumented information shall be available as evidence of the results of management reviews.\n10  Improvement\n\n10.1  Continual improvement"
  },
  {
    "chunk_id": "chunk_80",
    "content": "Documented information shall be available as evidence of the results of management reviews.\n10  Improvement\n\n10.1  Continual improvement\n\nThe  organization  shall  continually  improve  the  suitability,  adequacy  and  effectiveness  of  the  AI \nmanagement system.\n\n© ISO/IEC 2023 – All rights reserved \n\n15\n\n \n \n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\n10.2  Nonconformity and corrective action\n\nWhen a nonconformity occurs, the organization shall:\n\na)  react to the nonconformity and as applicable:\n\n1) \n\ntake action to control and correct it;\n\n2)  deal with the consequences;\n\nb)  evaluate the need for action to eliminate the cause(s) of the nonconformity, so that it does not recur \n\nor occur elsewhere, by:\n\n1)  reviewing the nonconformity;\n\n2)  determining the causes of the nonconformity;"
  },
  {
    "chunk_id": "chunk_81",
    "content": "or occur elsewhere, by:\n\n1)  reviewing the nonconformity;\n\n2)  determining the causes of the nonconformity;\n\n3)  determining if similar nonconformities exist or can potentially occur;\n\nc) \n\nimplement any action needed;\n\nd)  review the effectiveness of any corrective action taken;\n\ne)  make changes to the AI management system, if necessary.\n\nCorrective actions shall be appropriate to the effects of the nonconformities encountered.\n\nDocumented information shall be available as evidence of:\n\n—  the nature of the nonconformities and any subsequent actions taken;\n\n—  the results of any corrective action.\n\n16\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nAnnex A \n\n(normative) \nReference control objectives and controls\n\nA.1  General"
  },
  {
    "chunk_id": "chunk_82",
    "content": "ISO/IEC 42001:2023(E)\n\nAnnex A \n\n(normative) \nReference control objectives and controls\n\nA.1  General\n\nThe controls detailed in Table A.1 provide the organization with a reference for meeting organizational \nobjectives and addressing risks related to the design and operation of AI systems. Not all the control \nobjectives and controls listed in Table A.1 are required to be used, and the organization can design and \nimplement their own controls (see 6.1.3).\n\nAnnex B provides implementation guidance for all the controls listed in Table A.1.\n\nTable A.1 — Control objectives and controls\n\nA.2 Policies related to AI\n\nObjective: To provide management direction and support for AI systems according to business requirements.\n\nA.2.2\n\nA.2.3\n\nTopic\n\nAI policy\n\nAlignment with other organiza-\ntional policies\n\nA.2.4\n\nReview of the AI policy\n\nA.3 Internal organization\n\nControl\n\nThe organization shall document a policy for the develop-\nment or use of AI systems."
  },
  {
    "chunk_id": "chunk_83",
    "content": "A.2.4\n\nReview of the AI policy\n\nA.3 Internal organization\n\nControl\n\nThe organization shall document a policy for the develop-\nment or use of AI systems.\n\nThe organization shall determine where other policies can \nbe affected by or apply to, the organization’s objectives \nwith respect to AI systems.\n\nThe AI policy shall be reviewed at planned intervals or \nadditionally as needed to ensure its continuing suitability, \nadequacy and effectiveness.\n\nObjective: To establish accountability within the organization to uphold its responsible approach for the imple-\nmentation, operation and management of AI systems.\n\nTopic\n\nControl\n\nA.3.2\n\nA.3.3\n\nAI roles and responsibilities\n\nReporting of concerns\n\nA.4 Resources for AI systems\n\nRoles and responsibilities for AI shall be defined and allo-\ncated according to the needs of the organization."
  },
  {
    "chunk_id": "chunk_84",
    "content": "AI roles and responsibilities\n\nReporting of concerns\n\nA.4 Resources for AI systems\n\nRoles and responsibilities for AI shall be defined and allo-\ncated according to the needs of the organization.\n\nThe organization shall define and put in place a process to \nreport concerns about the organization’s role with respect \nto an AI system throughout its life cycle.\n\nObjective: To ensure that the organization accounts for the resources (including AI system components and \nassets) of the AI system in order to fully understand and address risks and impacts.\n\nTopic\n\nControl\n\nA.4.2\n\nResource documentation\n\nA.4.3\n\nData resources\n\nA.4.4\n\nTooling resources\n\n© ISO/IEC 2023 – All rights reserved \n\nThe organization shall identify and document relevant \nresources required for the activities at given AI system life \ncycle stages and other AI-related activities relevant for the \norganization."
  },
  {
    "chunk_id": "chunk_85",
    "content": "The organization shall identify and document relevant \nresources required for the activities at given AI system life \ncycle stages and other AI-related activities relevant for the \norganization.\n\nAs part of resource identification, the organization shall \ndocument information about the data resources utilized \nfor the AI system.\n\nAs part of resource identification, the organization shall \ndocument information about the tooling resources utilized \nfor the AI system.\n\n17\n\n \n \n \n \n \n \n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nTable A.1 (continued)\nTable A.1 (continued)\n\nA.4.5\n\nSystem and computing resources\n\nA.4.6\n\nHuman resources\n\nA.5 Assessing impacts of AI systems"
  },
  {
    "chunk_id": "chunk_86",
    "content": "Table A.1 (continued)\nTable A.1 (continued)\n\nA.4.5\n\nSystem and computing resources\n\nA.4.6\n\nHuman resources\n\nA.5 Assessing impacts of AI systems\n\nAs part of resource identification, the organization shall \ndocument information about the system and computing \nresources utilized for the AI system.\n\nAs part of resource identification, the organization shall \ndocument information about the human resources and \ntheir competences utilized for the development, deploy-\nment, operation, change management, maintenance, \ntransfer and decommissioning, as well as verification and \nintegration of the AI system.\n\nObjective: To assess AI system impacts to individuals or groups of individuals, or both, and societies affected \nby the AI system throughout its life cycle.\n\nTopic\n\nControl\n\nA.5.2\n\nA.5.3\n\nA.5.4\n\nAI system impact assessment \nprocess\n\nDocumentation of AI system im-\npact assessments\n\nAssessing AI system impact on in-\ndividuals or groups of individuals\n\nA.5.5"
  },
  {
    "chunk_id": "chunk_87",
    "content": "Control\n\nA.5.2\n\nA.5.3\n\nA.5.4\n\nAI system impact assessment \nprocess\n\nDocumentation of AI system im-\npact assessments\n\nAssessing AI system impact on in-\ndividuals or groups of individuals\n\nA.5.5\n\nAssessing societal impacts of AI \nsystems\nA.6 AI system life cycle\n\nThe organization shall establish a process to assess the \npotential consequences for individuals or groups of indi-\nviduals, or both, and societies that can result from the AI \nsystem throughout its life cycle.\n\nThe organization shall document the results of AI system \nimpact assessments and retain results for a defined peri-\nod.\n\nThe organization shall assess and document the potential \nimpacts of AI systems to individuals or groups of individu-\nals throughout the system’s life cycle.\n\nThe organization shall assess and document the potential \nsocietal impacts of their AI systems throughout their life \ncycle.\n\nA.6.1 Management guidance for AI system development"
  },
  {
    "chunk_id": "chunk_88",
    "content": "The organization shall assess and document the potential \nsocietal impacts of their AI systems throughout their life \ncycle.\n\nA.6.1 Management guidance for AI system development\n\nObjective: To ensure that the organization identifies and documents objectives and implements processes for \nthe responsible design and development of AI systems.\n\nTopic\n\nControl\n\nA.6.1.2\n\nObjectives for responsible develop-\nment of AI system\n\nA.6.1.3\n\nProcesses for responsible AI sys-\ntem design and development\n\nA.6.2 AI system life cycle\n\nThe organization shall identify and document objectives \nto guide the responsible development AI systems, and take \nthose objectives into account and integrate measures to \nachieve them in the development life cycle.\n\nThe organization shall define and document the specific \nprocesses for the responsible design and development of \nthe AI system.\n\nObjective: To define the criteria and requirements for each stage of the AI system life cycle.\n\nTopic\n\nControl"
  },
  {
    "chunk_id": "chunk_89",
    "content": "Objective: To define the criteria and requirements for each stage of the AI system life cycle.\n\nTopic\n\nControl\n\nAI system requirements and spec-\nification\n\nThe organization shall specify and document require-\nments for new AI systems or material enhancements to \nexisting systems.\n\nDocumentation of AI system design \nand development\n\nThe organization shall document the AI system design and \ndevelopment based on organizational objectives, docu-\nmented requirements and specification criteria.\n\nA.6.2.2\n\nA.6.2.3\n\nA.6.2.4\n\nAI system verification and valida-\ntion\n\nThe organization shall define and document verification \nand validation measures for the AI system and specify \ncriteria for their use.\n\nThe organization shall document a deployment plan and \nensure that appropriate requirements are met prior to \ndeployment.\n\n© ISO/IEC 2023 – All rights reserved\n\nA.6.2.5\n\nAI system deployment\n\n18"
  },
  {
    "chunk_id": "chunk_90",
    "content": "The organization shall document a deployment plan and \nensure that appropriate requirements are met prior to \ndeployment.\n\n© ISO/IEC 2023 – All rights reserved\n\nA.6.2.5\n\nAI system deployment\n\n18\n\n \n \n \n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nTable A.1 (continued)\nTable A.1 (continued)\n\nA.6.2.6\n\nAI system operation and monitor-\ning\n\nThe organization shall define and document the necessary \nelements for the ongoing operation of the AI system. At the \nminimum, this should include system and performance \nmonitoring, repairs, updates and support.\n\nA.6.2.7\n\nAI system technical documentation The organization shall determine what AI system techni-\n\nA.6.2.8\n\nAI system recording of event logs\n\nA.7 Data for AI systems\n\n:"
  },
  {
    "chunk_id": "chunk_91",
    "content": "A.6.2.7\n\nAI system technical documentation The organization shall determine what AI system techni-\n\nA.6.2.8\n\nAI system recording of event logs\n\nA.7 Data for AI systems\n\n:\n\ncal documentation is needed for each relevant category of \ninterested parties, such as users, partners, supervisory \nauthorities, and provide the technical documentation to \nthem in the appropriate form.\n\nThe organization shall determine at which phases of the \nAI system life cycle, record keeping of event logs should be \nenabled, but at the minimum when the AI system is in use.\n\nObjective\ncation and development, provision or use of AI systems throughout their life cycles.\n\n To ensure that the organization understands the role and impacts of data in AI systems in the appli-\n\nTopic\n\nControl\n\nA.7.2\n\nData for development and enhance-\nment of AI system\n\nA.7.3\n\nAcquisition of data\n\nA.7.4\n\nQuality of data for AI systems\n\nA.7.5\n\nData provenance\n\nA.7.6\n\nData preparation\n\nA.8 Information for interested parties of AI systems"
  },
  {
    "chunk_id": "chunk_92",
    "content": "A.7.3\n\nAcquisition of data\n\nA.7.4\n\nQuality of data for AI systems\n\nA.7.5\n\nData provenance\n\nA.7.6\n\nData preparation\n\nA.8 Information for interested parties of AI systems\n\nThe organization shall define, document and implement \ndata management processes related to the development of \nAI systems.\n\nThe organization shall determine and document details \nabout the acquisition and selection of the data used in AI \nsystems.\n\nThe organization shall define and document requirements \nfor data quality and ensure that data used to develop and \noperate the AI system meet those requirements.\n\nThe organization shall define and document a process for \nrecording the provenance of data used in its AI systems \nover the life cycles of the data and the AI system.\n\nThe organization shall define and document its criteria \nfor selecting data preparations and the data preparation \nmethods to be used."
  },
  {
    "chunk_id": "chunk_93",
    "content": "The organization shall define and document its criteria \nfor selecting data preparations and the data preparation \nmethods to be used.\n\nObjective: To ensure that relevant interested parties have the necessary information to understand and assess \nthe risks and their impacts (both positive and negative).\n\nTopic\n\nControl\n\nA.8.2\n\nA.8.3\n\nA.8.4\n\nA.8.5\n\nSystem documentation and infor-\nmation for users\n\nThe organization shall determine and provide the neces-\nsary information to users of the AI system.\n\nExternal reporting\n\nCommunication of incidents\n\nThe organization shall provide capabilities for interested \nparties to report adverse impacts of the AI system.\n\nThe organization shall determine and document a plan for \ncommunicating incidents to users of the AI system.\n\nInformation for interested parties The organization shall determine and document their \n\nA.9 Use of AI systems\n\nobligations to reporting information about the AI system \nto interested parties."
  },
  {
    "chunk_id": "chunk_94",
    "content": "Information for interested parties The organization shall determine and document their \n\nA.9 Use of AI systems\n\nobligations to reporting information about the AI system \nto interested parties.\n\nObjective: To ensure that the organization uses AI systems responsibly and per organizational policies.\n\nTopic\n\nControl\n\nA.9.2\n\nA.9.3\n\nProcesses for responsible use of AI \nsystems\n\nThe organization shall define and document the processes \nfor the responsible use of AI systems.\n\nObjectives for responsible use of AI \nsystem\n\nThe organization shall identify and document objectives to \nguide the responsible use of AI systems.\n\n© ISO/IEC 2023 – All rights reserved \n\n19\n\n \n \n \n \n \n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nTable A.1 (continued)\nTable A.1 (continued)\n\nA.9.4\n\nIntended use of the AI system"
  },
  {
    "chunk_id": "chunk_95",
    "content": "Table A.1 (continued)\nTable A.1 (continued)\n\nA.9.4\n\nIntended use of the AI system\n\nA.10 Third-party and customer relationships\n\nThe organization shall ensure that the AI system is used \naccording to the intended uses of the AI system and its \naccompanying documentation.\n\nObjective: To ensure that the organization understands its responsibilities and remains accountable, and risks \nare appropriately apportioned when third parties are involved at any stage of the AI system life cycle.\n\nTopic\n\nControl\n\nA.10.2\n\nAllocating responsibilities\n\nA.10.3\n\nSuppliers\n\nA.10.4\n\nCustomers\n\nThe organization shall ensure that responsibilities within \ntheir AI system life cycle are allocated between the organi-\nzation, its partners, suppliers, customers and third parties.\n\nThe organization shall establish a process to ensure that \nits usage of services, products or materials provided by \nsuppliers aligns with the organization’s approach to the \nresponsible development and use of AI systems."
  },
  {
    "chunk_id": "chunk_96",
    "content": "The organization shall ensure that its responsible ap-\nproach to the development and use of AI systems considers \ntheir customer expectations and needs.\n\n20\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nAnnex B \n\n(normative) \nImplementation guidance for AI controls\n\nB.1  General\n\nThe implementation guidance documented in this annex relates to the controls listed in Table A.1. It \nprovides  information  to  support  the  implementation  of  the  controls  listed  in  Table  A.1  and  to  meet \nthe  control  objective,  but  organizations  do  not  have  to  document  or  justify  inclusion  or  exclusion  of \nimplementation guidance in the statement of applicability (see 6.1.3)."
  },
  {
    "chunk_id": "chunk_97",
    "content": "The implementation guidance is not always suitable or sufficient in all situations and does not always \nfulfil  the  organization’s  specific  control  requirements.  The  organization  can  extend  or  modify  the \nimplementation guidance or define their own implementation of a control according to their specific \nrequirements and risk treatment needs.\n\nThis annex is to be used as guidance for determining and implementing controls for AI risk treatment \nin  the  AI  management  system  defined  in  this  document.  Additional  organizational  and  technical \ncontrols other than those included in this annex can be determined (see AI system management risk \ntreatment in 6.1.3). This annex can be regarded as a starting point for developing organization-specific \nimplementation of controls.\nB.2  Policies related to AI\n\nB.2.1  Objective\n\nTo provide management direction and support for AI systems according to business requirements.\nB.2.2  AI policy\n\nControl"
  },
  {
    "chunk_id": "chunk_98",
    "content": "B.2.1  Objective\n\nTo provide management direction and support for AI systems according to business requirements.\nB.2.2  AI policy\n\nControl\n\nImplementation guidance\nThe organization should document a policy for the development or use of AI systems.\n\nThe AI policy should be informed by:\n\n—  business strategy;\n\n—  organizational values and culture and the amount of risk the organization is willing to pursue or \n\nretain;\n\n—  the level of risk posed by the AI systems;\n\n— \n\nlegal requirements, including contracts;\n\n—  the risk environment of the organization;\n\n— \n\nimpact to relevant interested parties (see 6.1.4).\n\nThe AI policy should include (in addition to requirements in 5.2):\n\n—  principles that guide all activities of the organization related to AI;\n\n© ISO/IEC 2023 – All rights reserved \n\n21\n\n \n \n \n\fISO/IEC 42001:2023(E)"
  },
  {
    "chunk_id": "chunk_99",
    "content": "—  principles that guide all activities of the organization related to AI;\n\n© ISO/IEC 2023 – All rights reserved \n\n21\n\n \n \n \n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\n—  processes for handling deviations and exceptions to policy.\n\nThe AI policy should consider topic-specific aspects where necessary to provide additional guidance or \nprovide cross-references to other policies dealing with these aspects. Examples of such topics include:\n\n—  AI resources and assets;\n\n—  AI system impact assessments (see 6.1.4);\n\n—  AI system development.\n\nRelevant policies should guide the development, purchase, operation and use of AI systems.\nB.2.3  Alignment with other organizational policies\n\nControl"
  },
  {
    "chunk_id": "chunk_100",
    "content": "—  AI system development.\n\nRelevant policies should guide the development, purchase, operation and use of AI systems.\nB.2.3  Alignment with other organizational policies\n\nControl\n\nThe organization should determine where other policies can be affected by or apply to, the organization’s \nImplementation guidance\nobjectives with respect to AI systems.\n\nMany  domains  intersect  with  AI,  including  quality,  security,  safety  and  privacy.  The  organization \nshould consider a thorough analysis to determine whether and where current policies can necessarily \nOther information\nintersect and either update those policies if updates are required or include provisions in the AI policy.\n\nThe  policies  that  the  governing  body  sets  on  behalf  of  the  organization  should  inform  the  AI  policy. \nISO/IEC 38507 provides guidance for members of the governing body of an organization to enable and \ngovern the AI system throughout its life cycle.\nB.2.4  Review of the AI policy\n\nControl"
  },
  {
    "chunk_id": "chunk_101",
    "content": "Control\n\nThe AI policy should be reviewed at planned intervals or additionally as needed to ensure its continuing \nImplementation guidance\nsuitability, adequacy and effectiveness.\n\nA  role  approved  by  management  should  be  responsible  for  the  development,  review  and  evaluation \nof  the  AI  policy,  or  the  components  within.  The  review  should  include  assessing  opportunities  for \nimprovement of the organization’s policies and approach to managing AI systems in response to changes \nto the organizational environment, business circumstances, legal conditions or technical environment.\n\nThe review of AI policy should take the results of management reviews into account.\nB.3  Internal organization\n\nB.3.1  Objective\n\nTo  establish  accountability  within  the  organization  to  uphold  its  responsible  approach  for  the \nimplementation, operation and management of AI systems.\nB.3.2  AI roles and responsibilities\n\nControl"
  },
  {
    "chunk_id": "chunk_102",
    "content": "Control\n\nRoles  and  responsibilities  for  AI  should  be  defined  and  allocated  according  to  the  needs  of  the \norganization.\n22\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nImplementation guidance\n\nDefining roles and responsibilities is critical for ensuring accountability throughout the organization \nfor its role with respect to the AI system throughout its life cycle. The organization should consider AI \npolicies, AI objectives and identified risks when assigning roles and responsibilities, in order to ensure \nthat all relevant areas are covered. The organization can prioritize how the roles and responsibilities \nare assigned. Examples of areas that can require defined roles and responsibilities can include:\n\n—  risk management;"
  },
  {
    "chunk_id": "chunk_103",
    "content": "—  risk management;\n\n—  AI system impact assessments;\n\n—  asset and resource management;\n\n—  security;\n\n—  safety;\n\n—  privacy;\n\n—  development;\n\n—  performance;\n\n—  human oversight;\n\n—  supplier relationships;\n\n—  demonstrate its ability to consistently fulfil legal requirements;\n\n—  data quality management (during the whole life cycle).\n\nResponsibilities  of  the  various  roles  should  be  defined  to  the  level  appropriate  for  the  individuals  to \nperform their duties.\nB.3.3  Reporting of concerns\n\nControl\n\nThe organization should define and put in place a process to report concerns about the organization’s \nImplementation guidance\nrole with respect to an AI system throughout its life cycle.\n\nThe reporting mechanism should fulfil the following functions:\n\na)  options for confidentiality or anonymity or both;\n\nb)  available and promoted to employed and contracted persons;\n\nc)  staffed with qualified persons;"
  },
  {
    "chunk_id": "chunk_104",
    "content": "a)  options for confidentiality or anonymity or both;\n\nb)  available and promoted to employed and contracted persons;\n\nc)  staffed with qualified persons;\n\nd)  stipulates appropriate investigation and resolution powers for the persons referred to in c);\n\ne)  provides for mechanisms to report and to escalate to management in a timely manner;\n\nf)  provides for effective protection from reprisals for both the persons concerned with reporting and \n\ninvestigation (e.g. by allowing reports to be made anonymously and confidentially);\n\ng)  provides  reports  according  to  4.4  and,  if  appropriate,  e);  while  maintaining  confidentiality  and \n\nanonymity in a), and respecting general business confidentiality considerations;\n\nh)  provides response mechanisms within an appropriate time frame.\n\n23\n\n© ISO/IEC 2023 – All rights reserved \n\n \n \n\fISO/IEC 42001:2023(E)"
  },
  {
    "chunk_id": "chunk_105",
    "content": "h)  provides response mechanisms within an appropriate time frame.\n\n23\n\n© ISO/IEC 2023 – All rights reserved \n\n \n \n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nOther information\nNOTE \n\nThe organization can utilize existing reporting mechanisms as part of this process.\n\nIn  addition  to  the  implementation  guidance  provided  in  this  clause,  the  organization  should  further \nconsider ISO 37002.\nB.4  Resources for AI systems\n\nB.4.1  Objective\n\nTo ensure that the organization accounts for the resources (including AI system components and assets) \nof the AI system in order to fully understand and address risks and impacts.\nB.4.2  Resource documentation\n\nControl"
  },
  {
    "chunk_id": "chunk_106",
    "content": "Control\n\nThe organization should identify and document relevant resources required for the activities at given \nImplementation guidance\nAI system life cycle stages and other AI-related activities relevant for the organization.\n\nDocumentation  of  resources  of  the  AI  system  is  critical  for  understanding  risks,  as  well  as  potential \nAI  system  impacts  (both  positive  and  negative)  to  individuals  or  groups  of  individuals,  or  both,  and \nsocieties. The documentation of such resources (which can utilize, for instance, data flow diagrams or \nsystem architecture diagrams) can inform the AI system impact assessments (see B.5).\n\nResources can include, but are not limited to:\n\n—  AI system components;\n\n—  data resources, i.e. data used at any stage in the AI system life cycle;\n\n—  tooling resources (e.g. AI algorithms, models or tools);\n\n—  system and computing resources (e.g. hardware to develop and run AI models, storage for data and \n\ntooling resources);"
  },
  {
    "chunk_id": "chunk_107",
    "content": "—  tooling resources (e.g. AI algorithms, models or tools);\n\n—  system and computing resources (e.g. hardware to develop and run AI models, storage for data and \n\ntooling resources);\n\n—  human resources, i.e. people with the necessary expertise (e.g. for the development, sales, training, \noperation and maintenance of the AI system) in relation to the organization’s role throughout the AI \nsystem life cycle.\n\nOther information\nResources can be provided by the organization itself, by its customers or by third parties.\n\nDocumentation of resources can also help to determine if resources are available and, if they are not \navailable,  the  organization  should  revise  the  design  specification  of  the  AI  system  or  its  deployment \nrequirements.\nB.4.3  Data resources\n\nControl\n\nAs  part  of  resource  identification,  the  organization  should  document  information  about  the  data \nresources utilized for the AI system.\n\n24\n\n© ISO/IEC 2023 – All rights reserved"
  },
  {
    "chunk_id": "chunk_108",
    "content": "Control\n\nAs  part  of  resource  identification,  the  organization  should  document  information  about  the  data \nresources utilized for the AI system.\n\n24\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nImplementation guidance\n\nDocumentation on data should include, but is not limited to, the following topics:\n\n—  the provenance of the data;\n\n—  the date that the data were last updated or modified (e.g. date tag in metadata);\n\n— \n\nfor machine learning, the categories of data (e.g. training, validation, test and production data);\n\n—  categories of data (e.g. as defined in ISO/IEC 19944-1);\n\n—  process for labelling data;\n\n— \n\nintended use of the data;\n\n—  quality of data (e.g. as described in the ISO/IEC 5259 series\n\n2)\n\n);"
  },
  {
    "chunk_id": "chunk_109",
    "content": "—  categories of data (e.g. as defined in ISO/IEC 19944-1);\n\n—  process for labelling data;\n\n— \n\nintended use of the data;\n\n—  quality of data (e.g. as described in the ISO/IEC 5259 series\n\n2)\n\n);\n\n—  applicable data retention and disposal policies;\n\n—  known or potential bias issues in the data;\n\n—  data preparation.\nB.4.4  Tooling resources\n\nControl\n\nAs  part  of  resource  identification,  the  organization  should  document  information  about  the  tooling \nImplementation guidance\nresources utilized for the AI system.\n\nTooling  resources  for  an  AI  system  and  particularly  for  machine  learning,  can  include  but  are  not \nlimited to:\n\n—  algorithm types and machine learning models;\n\n—  data conditioning tools or processes;\n\n—  optimization methods;\n\n—  evaluation methods;\n\n—  provisioning tools for resources;\n\n—  tools to aid model development;\n\nOther information\n—  software and hardware for AI system design, development and deployment."
  },
  {
    "chunk_id": "chunk_110",
    "content": "—  evaluation methods;\n\n—  provisioning tools for resources;\n\n—  tools to aid model development;\n\nOther information\n—  software and hardware for AI system design, development and deployment.\n\nISO/IEC 23053 provides detailed guidance on the types, methods and approaches for various tooling \nresources for machine learning.\nB.4.5  System and computing resources\n\nControl\n\nAs part of resource identification, the organization should document information about the system and \ncomputing resources utilized for the AI system.\n\n2) \nIEC DIS 5259-3:2023, ISO/IEC DIS 5259-4:2023, ISO/IEC CD 5259-5:2023.\n\n Under preparation. Stage at the time of publication: ISO/IEC DIS 5259-1:2023, ISO/IEC DIS 5259-2:2023, ISO/\n25\n\n© ISO/IEC 2023 – All rights reserved \n\n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nImplementation guidance"
  },
  {
    "chunk_id": "chunk_111",
    "content": "ISO/IEC 42001:2023(E)\n\nImplementation guidance\n\nInformation about system and computing resources for an AI system can include but is not limited to:\n\n—  resource  requirements  of  the  AI  system  (i.e.  to  help  ensure  the  system  can  run  on  constrained \n\nresource devices);\n\n—  where the system and computing resources are located (e.g. on-premises, cloud computing or edge \n\ncomputing);\n\n—  processing resources (including network and storage);\n\n—  the impact of the hardware used to run the AI system workloads (e.g. the impact to the environment \n\neither through use or the manufacturing of the hardware or cost of using the hardware).\n\nThe  organization  should  consider  that  different  resources  can  be  required  to  allow  continual \nimprovement of AI systems. Development, deployment and operation of the system can have different \nsystem needs and requirements.\n\nNOTE \nB.4.6  Human resources\n\nISO/IEC 22989 describes various system resource considerations.\n\nControl"
  },
  {
    "chunk_id": "chunk_112",
    "content": "NOTE \nB.4.6  Human resources\n\nISO/IEC 22989 describes various system resource considerations.\n\nControl\n\nAs  part  of  resource  identification,  the  organization  should  document  information  about  the  human \nresources  and  their  competences  utilized  for  the  development,  deployment,  operation,  change \nmanagement, maintenance, transfer and decommissioning, as well as verification and integration of the \nImplementation guidance\nAI system.\n\nThe organization should consider the need for diverse expertise and include the types of roles necessary \nfor the system. For example, the organization can include specific demographic groups related to data \nsets used to train machine learning models, if their inclusion is a necessary component of the system \ndesign. Necessary human resources can include but are not limited to:\n\n—  data scientists;\n\n—  roles related to human oversight of AI systems;\n\n—  experts on trustworthiness topics such as safety, security and privacy;"
  },
  {
    "chunk_id": "chunk_113",
    "content": "—  data scientists;\n\n—  roles related to human oversight of AI systems;\n\n—  experts on trustworthiness topics such as safety, security and privacy;\n\n—  AI researchers and specialists, and domain experts relevant to the AI systems.\n\nDifferent resources can be necessary at different stages of the AI system life cycle.\nB.5  Assessing impacts of AI systems\n\nB.5.1  Objective\n\nTo assess AI system impacts to individuals or groups of individuals, or both, and societies affected by \nthe AI system throughout its life cycle.\nB.5.2  AI system impact assessment process\n\nControl\n\nThe  organization  should  establish  a  process  to  assess  the  potential  consequences  for  individuals  or \ngroups of individuals, or both, and societies that can result from the AI system throughout its life cycle.\n\n26\n\n© ISO/IEC 2023 – All rights reserved"
  },
  {
    "chunk_id": "chunk_114",
    "content": "26\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nImplementation guidance\n\nBecause  AI  systems  potentially  generate  significant  impact  to  individuals,  groups  of  individuals  ,  or \nboth, and societies, the organization that provides and uses such systems should, based on the intended \npurpose and use of these systems, assess the potential impacts of these systems on these groups.\n\nThe organization should consider whether an AI system affects:\n\n—  the legal position or life opportunities of individuals;\n\n—  the physical or psychological well-being of individuals;\n\n—  universal human rights;\n\n—  societies.\n\nThe organization’s procedures should include, but are not limited to:"
  },
  {
    "chunk_id": "chunk_115",
    "content": "—  the physical or psychological well-being of individuals;\n\n—  universal human rights;\n\n—  societies.\n\nThe organization’s procedures should include, but are not limited to:\n\na)  circumstances  under  which  an  AI  system  impact  assessment  should  be  performed,  which  can \n\ninclude, but are not limited to:\n\n1)  criticality of the intended purpose and context in which the AI system is used or any significant \n\nchanges to these;\n\n2)  complexity  of  AI  technology  and  the  level  of  automation  of  AI  systems  or  any  significant \n\nchanges to that;\n\n3)  sensitivity of data types and sources processed by the AI system or any significant changes to \n\nthat;\n\nb)  elements that are part of the AI system impact assessment process, which can include:\n\n1) \n\nidentification (e.g. sources, events and outcomes);\n\n2)  analysis (e.g. consequences and likelihood);\n\n3)  evaluation (e.g. acceptance decisions and prioritization);\n\n4) \n\ntreatment (e.g. mitigation measures);"
  },
  {
    "chunk_id": "chunk_116",
    "content": "2)  analysis (e.g. consequences and likelihood);\n\n3)  evaluation (e.g. acceptance decisions and prioritization);\n\n4) \n\ntreatment (e.g. mitigation measures);\n\n5)  documentation, reporting and communication (see 7.4, 7.5 and B.3.3);\n\nc)  who performs the AI system impact assessment;\n\nd)  how the AI system impact assessment can be utilized [e.g. how it can inform the design or use of the \n\nsystem (see B.6 and B.9), whether it can trigger reviews and approvals];\n\ne) \n\nindividuals  and  societies  that  are  potentially  impacted  based  on  the  system’s  intended  purpose, \nuse and characteristics (e.g. assessment for individuals, groups of individuals or societies).\n\nImpact assessment should take various aspects of the AI system into account, including the data used \nfor  the  development  of  the  AI  system,  the  AI  technologies  used  and  the  functionality  of  the  overall \nsystem."
  },
  {
    "chunk_id": "chunk_117",
    "content": "The  processes  can  vary  based  on  the  role  of  the  organization  and  the  domain  of  AI  application  and \nOther information\ndepending on the specific disciplines for which the impact is assessed (e.g. security, privacy and safety).\n\nFor  some  disciplines  or  organizations,  detailed  consideration  of  the  impact  on  individuals  or  groups \nof  individuals,  or  both,  and  societies  is  part  of  risk  management,  particularly  in  disciplines  such  as \ninformation  security,  safety  and  environmental  management.  The  organization  should  determine \n\n27\n\n© ISO/IEC 2023 – All rights reserved \n\n \n \n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited."
  },
  {
    "chunk_id": "chunk_118",
    "content": "Licensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nif  discipline-specific  impact  assessments  performed  as  part  of  such  a  risk  management  process \nsufficiently integrate AI considerations for those specific aspects (e.g. privacy).\n\nNOTE \nISO/IEC 23894 describes how an organization can perform impact analyses for the organization itself, \nalong  with  individuals  or  groups  of  individuals,  or  both,  and  societies,  as  part  of  an  overall  risk  management \nprocess.\nB.5.3  Documentation of AI system impact assessments\n\nControl\n\nThe organization should document the results of AI system impact assessments and retain results for a \nImplementation guidance\ndefined period.\n\nThe documentation can be helpful in determining information that should be communicated to users \nand other relevant interested parties."
  },
  {
    "chunk_id": "chunk_119",
    "content": "The documentation can be helpful in determining information that should be communicated to users \nand other relevant interested parties.\n\nAI  system  impact  assessments  should  be  retained  and  updated,  as  needed,  in  alignment  with  the \nelements  of  an  AI  system  impact  assessment  documented  in  B.5.2.  Retention  periods  can  follow \norganization retention schedules or be informed by legal requirements or other requirements.\n\nItems that the organization should consider documenting can include, but are not limited to:\n\n—  the intended use of the AI system and any reasonable foreseeable misuse of the AI system;\n\n—  positive and negative impacts of the AI system to the relevant individuals or groups of individuals, \n\nor both, and societies;\n\n—  predictable failures, their potential impacts and measures taken to mitigate them;\n\n—  relevant demographic groups the system is applicable to;\n\n—  complexity of the system;"
  },
  {
    "chunk_id": "chunk_120",
    "content": "—  predictable failures, their potential impacts and measures taken to mitigate them;\n\n—  relevant demographic groups the system is applicable to;\n\n—  complexity of the system;\n\n—  the role of humans in relationships with system, including human oversight capabilities, processes \n\nand tools, available to avoid negative impacts;\n\n—  employment and staff skilling.\nB.5.4  Assessing AI system impact on individuals or groups of individuals\n\nControl\n\nThe  organization  should  assess  and  document  the  potential  impacts  of  AI  systems  to  individuals  or \nImplementation guidance\ngroups of individuals throughout the system’s life cycle."
  },
  {
    "chunk_id": "chunk_121",
    "content": "The  organization  should  assess  and  document  the  potential  impacts  of  AI  systems  to  individuals  or \nImplementation guidance\ngroups of individuals throughout the system’s life cycle.\n\nWhen  assessing  the  impacts  on  individuals  or  groups  of  individuals,  or  both,  and  societies,  the \norganization  should  consider  its  governance  principles,  AI  policies  and  objectives.  Individuals  using \nthe  AI  system  or  whose  PII  are  processed  by  the  AI  system,  can  have  expectations  related  to  the \ntrustworthiness  of  the  AI  system.  Specific  protection  needs  of  groups  such  as  children,  impaired \npersons, elderly persons and workers should be taken into account. The organization should evaluate \nthese expectations and consider the means to address them as part of the system impact assessment."
  },
  {
    "chunk_id": "chunk_122",
    "content": "Depending  on  the  scope  of  AI  system  purpose  and  use,  areas  of  impact  to  consider  as  part  of  the \nassessment can include, but are not limited to:\n\n— \n\nfairness;\n\n—  accountability;\n28\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\n—  transparency and explainability;\n\n—  security and privacy;\n\n—  safety and health;\n\n— \n\nfinancial consequences;\n\n—  accessibility;\n\nOther information\n—  human rights.\n\nWhere necessary, the organization should consult experts (e.g. researchers, subject matter experts and \nusers) to obtain a full understanding of potential impacts of the AI system on individuals or groups of \nindividuals, or both, and societies.\nB.5.5  Assessing societal impacts of AI systems\n\nControl"
  },
  {
    "chunk_id": "chunk_123",
    "content": "Control\n\nThe  organization  should  assess  and  document  the  potential  societal  impacts  of  their  AI  systems \nImplementation guidance\nthroughout their life cycle.\n\nSocietal impacts can vary widely depending on the organization’s context and the types of AI systems. \nThe societal impacts of AI systems can be both beneficial and detrimental. Examples of these potential \nsocietal impacts can include:\n\n—  environment  sustainability  (including  the  impacts  on  natural  resources  and  greenhouse  gas \n\nemissions);\n\n—  economic  (including  access  to  financial  services,  employment  opportunities,  taxes,  trade  and \n\ncommerce);\n\n—  government  (including  legislative  processes,  misinformation  for  political  gain,  national  security \n\nand criminal justice systems);\n\n—  health and safety (including access to healthcare, medical diagnosis and treatment, and potential \n\nphysical and psychological harms);"
  },
  {
    "chunk_id": "chunk_124",
    "content": "and criminal justice systems);\n\n—  health and safety (including access to healthcare, medical diagnosis and treatment, and potential \n\nphysical and psychological harms);\n\n—  norms, traditions, culture and values (including misinformation that leads to biases or harms to \nOther information\n\nindividuals or groups of individuals, or both, and societies).\n\nDevelopment  and  use  of  AI  systems  can  be  computationally  intensive  with  related  impacts  to \nenvironmental  sustainability  (e.g.  greenhouse  gas  emissions  due  to  increased  power  usage,  impacts \non  water,  land,  flora  and  fauna).  Likewise,  AI  systems  can  be  used  to  improve  the  environmental \nsustainability  of  other  systems  (e.g.  reduce  greenhouse  gas  emissions  related  to  buildings  and \ntransportation).  The  organization  should  consider  the  impacts  of  its  AI  systems  in  the  context  of  its \noverall environmental sustainability goals and strategies."
  },
  {
    "chunk_id": "chunk_125",
    "content": "The organization should consider how its AI systems can be misused to create societal harms and how \nthey can be used to address historical harms. For example, can AI systems prevent access to financial \nservices such as loans, grants, insurance and investments and likewise can AI systems improve access \nto these instruments?\n\nAI systems have been used to influence the outcomes of elections and to create misinformation (e.g. \ndeepfakes in digital media) that can lead to political and social unrest. Government’s use of AI systems \nfor  criminal-justice  purposes  has  exposed  the  risk  of  biases  to  societies,  individuals  or  groups  of \n29\n\n© ISO/IEC 2023 – All rights reserved \n\n \n \n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited."
  },
  {
    "chunk_id": "chunk_126",
    "content": "Licensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nindividuals. The organization should analyse how actors can misuse AI systems and how the AI systems \ncan reinforce unwanted historical social biases.\n\nAI  systems  can  be  used  to  diagnose  and  treat  illnesses  and  to  determine  qualifications  for  health \nbenefits. AI systems are also deployed in scenarios where malfunctions can result in death or injury \nto humans (e.g. self-driving automobiles, human-machine teaming). The organization should consider \nboth the positive and negative outcomes when using AI systems, such as in health and safety related \nscenarios.\n\nISO/IEC  TR  24368  provides  a  high-level  overview  of  ethical  and  societal  concerns  related  to  AI \n\nNOTE \nsystems and applications.\nB.6  AI system life cycle\n\nB.6.1  Management guidance for AI system development"
  },
  {
    "chunk_id": "chunk_127",
    "content": "NOTE \nsystems and applications.\nB.6  AI system life cycle\n\nB.6.1  Management guidance for AI system development\n\nB.6.1.1  Objective\n\nTo ensure that the organization identifies and documents objectives and implements processes for the \nresponsible design and development of AI systems.\nB.6.1.2  Objectives for responsible development of AI system\n\nControl\n\nThe  organization  should  identify  and  document  objectives  to  guide  the  responsible  development \nof AI systems, and take those objectives into account and integrate measures to achieve them in the \nImplementation guidance\ndevelopment life cycle."
  },
  {
    "chunk_id": "chunk_128",
    "content": "The organization should identify objectives (see 6.2) that affect the AI system design and development \nprocesses.  These  objectives  should  be  taken  into  account  in  the  design  and  development  processes. \nFor  example,  if  an  organization  defines  “fairness”  as  one  objective,  this  should  be  incorporated  in \nthe  requirements  specification,  data  acquisition,  data  conditioning,  model  training,  verification  and \nvalidation, etc. The organization should provide requirements and guidelines as necessary to ensure \nthat measures are integrated into the various stages (e.g. the requirement to use a specific testing tool \nOther information\nor method to address unfairness or unwanted bias) to achieve such objectives."
  },
  {
    "chunk_id": "chunk_129",
    "content": "AI  techniques  are  being  used  to  augment  security  measures  such  as  threat  prediction  detection  and \nprevention  of  security  attacks.  This  is  an  application  of  AI  techniques  that  can  be  used  to  reinforce \nsecurity measures to protect both AI systems and conventional non-AI based software systems. Annex C \nprovides examples of organizational objectives for managing risk, which can be useful in determining \nthe objectives for AI system development.\nB.6.1.3  Processes for responsible design and development of AI systems\n\nControl\n\nThe  organization  should  define  and  document  the  specific  processes  for  the  responsible  design  and \ndevelopment of the AI system.\n\n30\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nImplementation guidance"
  },
  {
    "chunk_id": "chunk_130",
    "content": "ISO/IEC 42001:2023(E)\n\nImplementation guidance\n\nResponsible development for AI system processes should include consideration of, without limitation, \nthe following:\n\n— \n\nlife  cycle  stages  (a  generic  AI  system  life  cycle  model  is  provided  by  ISO/IEC  22989,  but  the \norganization can specify their own life cycle stages);\n\n—  testing requirements and planned means for testing;\n\n—  human oversight requirements, including processes and tools, especially when the AI system can \n\nimpact natural persons;\n\n—  at what stages AI system impact assessments should be performed;\n\n—  training  data  expectations  and  rules  (e.g.  what  data  can  be  used,  approved  data  suppliers  and \n\nlabelling);\n\n—  expertise  (subject  matter  domain  or  other)  required  or  training  for  developers  of  AI  systems  or \n\nboth;\n\n—  release criteria;\n\n—  approvals and sign-offs necessary at various stages;\n\n—  change control;\n\n—  usability and controllability;"
  },
  {
    "chunk_id": "chunk_131",
    "content": "both;\n\n—  release criteria;\n\n—  approvals and sign-offs necessary at various stages;\n\n—  change control;\n\n—  usability and controllability;\n\n—  engagement of interested parties.\n\nThe  specific  design  and  development  processes  depend  on  the  functionality  and  the  AI  technologies \nthat are intended to be used for the AI system.\nB.6.2  AI system life cycle\n\nB.6.2.1  Objective\n\nTo define the criteria and requirements for each stage of the AI system life cycle.\nB.6.2.2  AI system requirements and specification\n\nControl\n\nThe  organization  should  specify  and  document  requirements  for  new  AI  systems  or  material \nImplementation guidance\nenhancements to existing systems.\n\nThe organization should document the rationale for developing an AI system and its goals. Some of the \nfactors that should be considered, documented and understood can include:\n\na)  why  the  AI  system  is  to  be  developed,  for  example,  is  this  driven  by  a  business  case,  customer"
  },
  {
    "chunk_id": "chunk_132",
    "content": "a)  why  the  AI  system  is  to  be  developed,  for  example,  is  this  driven  by  a  business  case,  customer \n\nrequest or by government policy;\n\nb)  how the model can be trained and how data requirements can be achieved.\n\nAI  system  requirements  should  be  specified  and  should  span  the  entire  AI  system  life  cycle.  Such \nrequirements  should  be  revisited  in  cases  where  the  developed  AI  system  is  unable  to  operate  as \nintended or new information arises that can be used to change and to improve the requirements. For \ninstance, it can become unfeasible from a financial perspective to develop the AI system.\n\n31\n\n© ISO/IEC 2023 – All rights reserved \n\n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nOther information"
  },
  {
    "chunk_id": "chunk_133",
    "content": "ISO/IEC 42001:2023(E)\n\nOther information\n\nThe processes for describing the AI system life cycle are provided by ISO/IEC 5338. For more information \nabout human-centred design for interactive systems, see ISO 9241-210.\nB.6.2.3  Documentation of AI system design and development\n\nControl\n\nThe  organization  should  document  the  AI  system  design  and  development  based  on  organizational \nImplementation guidance\nobjectives, documented requirements and specification criteria.\n\nThere are many design choices necessary for an AI system, including, but not limited to:\n\n—  machine learning approach (e.g. supervised vs. unsupervised);\n\n— \n\nlearning algorithm and type of machine learning model utilized;\n\n—  how the model is intended to be trained and which data quality (see B.7);\n\n—  evaluation and refinement of models;\n\n—  hardware and software components;\n\n—  security  threats  considered  throughout  the  AI  system  life  cycle;  security  threats  specific  to  AI"
  },
  {
    "chunk_id": "chunk_134",
    "content": "—  evaluation and refinement of models;\n\n—  hardware and software components;\n\n—  security  threats  considered  throughout  the  AI  system  life  cycle;  security  threats  specific  to  AI \n\nsystems include data poisoning, model stealing or model inversion attacks;\n\n— \n\ninterface and presentation of outputs;\n\n—  how humans can interact with the system;\n\n— \n\ninteroperability and portability considerations.\n\nThere  can  be  multiple  iterations  between  design  and  development,  but  documentation  on  the  stage \nOther information\nshould be maintained and a final system architecture documentation should be available.\n\nFor more information about human-centred design for interactive systems, see ISO 9241-210.\nB.6.2.4  AI system verification and validation\n\nControl\n\nThe organization should define and document verification and validation measures for the AI system \nImplementation guidance\nand specify criteria for their use."
  },
  {
    "chunk_id": "chunk_135",
    "content": "Control\n\nThe organization should define and document verification and validation measures for the AI system \nImplementation guidance\nand specify criteria for their use.\n\nThe verification and validation measures can include, but are not limited to:\n\n—  testing methodologies and tools;\n\n—  selection of test data and their representation of the intended domain of use;\n\n—  release criteria requirements.\n\nThe organization should define and document evaluation criteria such as, but not limited to:\n\n—  a plan to evaluate the AI system components and the whole AI system for risks related to impacts \n\non individuals or groups of individuals, or both, and societies;\n\n32\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\n—  the evaluation plan can be based on, for example:"
  },
  {
    "chunk_id": "chunk_136",
    "content": "ISO/IEC 42001:2023(E)\n\n—  the evaluation plan can be based on, for example:\n\n—  reliability and safety requirements of the AI system, including acceptable error rates for the AI \n\nsystem performance;\n\n—  responsible AI system development and use objectives such as those in B.6.1.2 and B.9.3;\n\n—  operational factors such as quality of data, intended use, including acceptable ranges of each \n\noperational factor;\n\n—  any intended uses which can require more rigorous operational factors to be defined, including \n\ndifferent acceptable ranges for operational factors or lower error rates;\n\n—  the methods, guidance or metrics to be used to evaluate whether relevant interested parties who \nmake decisions or are subject to decisions based on the AI system outputs can adequately interpret \nthe AI system outputs. The frequency of evaluation should be determined and can be based upon \nresults from an AI system impact assessment;"
  },
  {
    "chunk_id": "chunk_137",
    "content": "—  any  acceptable  factors  that  can  account  for  an  inability  to  meet  a  target  minimum  performance \nlevel, especially when the AI system is evaluated for impacts on individuals or groups of individuals, \nor both, and societies (e.g. poor image resolution for computer vision systems or background noise \naffecting speech recognition systems). Mechanisms to deal with poor AI system performance as a \nresult of these factors should also be documented.\n\nThe AI system should be evaluated against the documented criteria for evaluation.\n\nWhere the AI system cannot meet the documented criteria for evaluation, especially against responsible \nAI system development and use objectives (see B.6.1.2 and B.9.3), the organization should reconsider or \nmanage the deficiencies of the intended use of the AI system, its performance requirements and how \nthe organization can effectively address the impacts to individuals or groups of individuals, or both, \nand societies."
  },
  {
    "chunk_id": "chunk_138",
    "content": "Further  information  on  how  to  deal  with  robustness  of  neural  networks  can  be  found  in \n\nNOTE \nISO/IEC TR 24029-1.\nB.6.2.5  AI system deployment\n\nControl\n\nThe organization should document a deployment plan and ensure that appropriate requirements are \nImplementation guidance\nmet prior to deployment."
  },
  {
    "chunk_id": "chunk_139",
    "content": "AI systems can be developed in various environments and deployed in others (such as developed on \npremises  and  deployed  using  cloud  computing)  and  the  organization  should  take  these  differences \ninto  account  for  the  deployment  plan.  The  organization  should  also  consider  whether  components \nare  deployed  separately  (e.g.  software  and  model  can  be  deployed  independently).  Additionally,  the \norganization should have a set of requirements to be met prior to release and deployment (sometimes \nreferred to as “release criteria”). This can include verification and validation measures that are to be \npassed, performance metrics that are to be met, user testing to be completed, as well as management \napprovals and sign-offs to be obtained. The deployment plan should take into account the perspectives \nof and impacts to relevant interested parties.\nB.6.2.6  AI system operation and monitoring\n\nControl"
  },
  {
    "chunk_id": "chunk_140",
    "content": "Control\n\nThe organization should define and document the necessary elements for the ongoing operation of the \nAI system. At the minimum this should include system and performance monitoring, repairs, updates \nand support.\n\n33\n\n© ISO/IEC 2023 – All rights reserved \n\n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nImplementation guidance\n\nEach minimum activity for operation and monitoring can take account of various considerations. For \nexample:"
  },
  {
    "chunk_id": "chunk_141",
    "content": "ISO/IEC 42001:2023(E)\n\nImplementation guidance\n\nEach minimum activity for operation and monitoring can take account of various considerations. For \nexample:\n\n—  System and performance monitoring can include monitoring for general errors and failures, as well \nas for whether the system is performing as expected with production data. Technical performance \ncriteria can include success rates in resolving problems or in achieving tasks, or confidence rates. \nOther criteria can be related to meeting commitment or expectation and needs of interested parties, \nincluding, for example, ongoing monitoring to ensure compliance with customer requirements or \napplicable legal requirements."
  },
  {
    "chunk_id": "chunk_142",
    "content": "—  Some  deployed  AI  systems  evolve  their  performance  as  a  result  of  ML,  where  production  data \nand output data are used to further train the ML model. Where continuous learning is used, the \norganization should monitor the performance of the AI system to ensure that it continues to meet \nits design goals and operates on production data as intended.\n\n—  The performance of some AI systems can change even if such systems do not use continuous learning, \nusually due to concept or data drift in production data. In such cases, monitoring can identify the \nneed for retraining to ensure that the AI system continues to meet its design goals and operates on \nproduction data as intended. More information can be found in ISO/IEC 23053."
  },
  {
    "chunk_id": "chunk_143",
    "content": "—  Repairs can include responses to errors and failures in the system. The organization should have \nprocesses in place for the response and repair of these issues. Additionally, updates can be necessary \nas the system evolves or as critical issues are identified, or as the result of externally identified issues \n(e.g. non-compliance with customer expectations or legal requirement). There should be processes \nin place for updating the system including components affected, update schedule, information to \nusers on what is included in the update.\n\n—  System updates can also include changes in the system operations, new or modified intended uses, \nor  other  changes  in  system  functionality.  The  organization  should  have  procedures  in  place  to \naddress operational changes, including communication to users."
  },
  {
    "chunk_id": "chunk_144",
    "content": "—  Support for the system can be internal, external or both, depending on the needs of the organization \nand how the system was acquired. Support processes should consider how users can contact the \nappropriate  help,  how  issues  and  incidents  are  reported,  support  service  level  agreements  and \nmetrics.\n\n—  Where AI systems are being used for purposes other than those for which they were designed or in \n\nways that were not anticipated, the appropriateness of such uses should be considered.\n\n—  AI-specific  information  security  threats  related  to  the  AI  systems  applied  and  developed  by  the \norganization  should  be  identified.  AI-specific  information  security  threats  include,  but  are  not \nlimited to data poisoning, model stealing and model inversion attacks.\n\nOther information\n\nThe  organization  should  consider  operational  performance  that  can  affect  interested  parties  and \nconsider this when designing and determining performance criteria."
  },
  {
    "chunk_id": "chunk_145",
    "content": "Other information\n\nThe  organization  should  consider  operational  performance  that  can  affect  interested  parties  and \nconsider this when designing and determining performance criteria.\n\nPerformance criteria for AI systems in operation should be determined by the task under consideration, \nsuch as classification, regression, ranking, clustering or dimensionality reduction.\n\nPerformance  criteria  can  include  statistical  aspects  such  as  error  rates  and  processing  duration. \nFor  each  criterion,  the  organization  should  identify  all  relevant  metrics  as  well  as  interdependences \nbetween  metrics.  For  each  metric,  the  organization  should  consider  acceptable  values  based  on,  for \nexample, domain expert’s recommendations and analysis of expectations of interested parties relative \nto existing non-AI practices.\n\nF"
  },
  {
    "chunk_id": "chunk_146",
    "content": "F\n\n1  score  is  an  appropriate  performance \nFor  example,  an  organization  can  determine  that  the \nmetric  based  on  its  assessment  of  the  impact  of  false  positives  and  false  negatives,  as  described  in \n34\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nF\n\n1  value  that  the  AI  system  is  expected  to \nISO/IEC  TS  4213.  The  organization  can  then  establish  an \nmeet. It should be evaluated if these issues can be handled by existing measures. If that is not the case, \nchanges to existing measures should be considered or additional measures should be defined to detect \nand handle these issues."
  },
  {
    "chunk_id": "chunk_147",
    "content": "The organization should consider the performance of non-AI systems or processes in operation and use \nthem as potentially relevant context when establishing performance criteria.\n\nThe  organization  should  additionally  ensure  that  the  means  and  processes  used  to  evaluate  the  AI \nsystem,  including,  where  applicable,  the  selection  and  management  of  evaluation  data,  improve  the \ncompleteness and the reliability in assessment of its performance with respect to the defined criteria.\n\nDevelopment of performance assessment methodologies can be based on criteria, metrics and values. \nThese  should  inform  the  amount  of  data  and  the  types  of  processes  used  in  the  assessment  and  the \nroles and expertise of personnel that carries out the assessment."
  },
  {
    "chunk_id": "chunk_148",
    "content": "Performance  assessment  methodologies  should  reflect  attributes  and  characteristics  of  operation \nand use as closely as possible to ensure that assessment results are useful and relevant. Some aspects \nof  performance  assessment  can  require  controlled  introduction  of  erroneous  or  spurious  data  or \nprocesses to assess impact on performance.\n\nThe quality model in ISO/IEC 25059 can be used to define performance criteria.\nB.6.2.7  AI system technical documentation\n\nControl\n\nThe  organization  should  determine  what  AI  system  technical  documentation  is  needed  for  each \nrelevant category of interested parties, such as users, partners, supervisory authorities, and provide \nImplementation guidance\nthe technical documentation to them in the appropriate form.\n\nThe AI system technical documentation can include, but is not limited to the following elements:\n\n—  a general description of the AI system including its intended purpose;\n\n—  usage instructions;"
  },
  {
    "chunk_id": "chunk_149",
    "content": "The AI system technical documentation can include, but is not limited to the following elements:\n\n—  a general description of the AI system including its intended purpose;\n\n—  usage instructions;\n\n—  technical assumptions about its deployment and operation (run-time environment, related software \n\nand hardware capabilities, assumptions made on data, etc.);\n\n—  technical limitations (e.g. acceptable error rates, accuracy, reliability, robustness);\n\n—  monitoring  capabilities  and  functions  that  allow  users  or  operators  to  influence  the  system \n\noperation.\n\nDocumentation  elements  related  to  all  AI  system  life  cycle  stages  (as  defined  in  ISO/IEC  22989)  can \ninclude, but are not limited to:\n\n—  design and system architecture specification;\n\n—  design choices made and quality measures taken during the system development process;\n\n— \n\ninformation about the data used during system development;"
  },
  {
    "chunk_id": "chunk_150",
    "content": "—  design choices made and quality measures taken during the system development process;\n\n— \n\ninformation about the data used during system development;\n\n—  assumptions made and quality measures taken on data quality (e.g. assumed statistical distributions);\n\n—  management  activities  (e.g.  risk  management)  taken  during  development  or  operation  of  the  AI \n\nsystem;\n\n—  verification and validation records;\n\n© ISO/IEC 2023 – All rights reserved \n\n35\n\n \n \n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\n—  changes made to the AI system when it is in operation;\n\n— \n\nimpact assessment documentation as described in B.5.\n\nThe organization should document technical information related to the responsible operation of the AI \nsystem. This can include, but is not limited to:"
  },
  {
    "chunk_id": "chunk_151",
    "content": "The organization should document technical information related to the responsible operation of the AI \nsystem. This can include, but is not limited to:\n\n—  documenting  a  plan  for  managing  failures.  This  can  include  for  example,  the  need  to  describe  a \nrollback plan for the AI system, turning off features of the AI system, an update process or a plan for \nnotifying customers, users, etc. of changes to the AI system, updated information on system failures \nand how these can be mitigated;\n\n—  documenting processes for monitoring the health of the AI system (i.e. the AI system operates as \nintended and within its normal operating margins, also referred to as observability) and processes \nfor addressing AI system failures;\n\n—  documenting standard operating procedures for the AI system, including which events should be \nmonitored and how event logs are prioritized and reviewed. It can also include how to investigate \nfailures and the prevention of failures;"
  },
  {
    "chunk_id": "chunk_152",
    "content": "—  documenting  the  roles  of  personnel  responsible  for  operation  of  the  AI  system  as  well  as  those \nresponsible for accountability of the system use, especially in relation to handling the effects of AI \nsystem failures or managing updates to the AI system;\n\n—  documenting system updates like changes in the system operations, new or modified intended uses, \n\nor other changes in system functionality.\n\nThe  organization  should  have  procedures  in  place  to  address  operational  changes  including \ncommunication to users and internal evaluations on the type of change.\n\nDocumentation should be up to date and accurate. Documentation should be approved by the relevant \nmanagement within the organization.\n\nWhen provided as part of the user documentation, the controls provided in Table A.1 should be taken \ninto account.\nB.6.2.8  AI system recording of event logs\n\nControl"
  },
  {
    "chunk_id": "chunk_153",
    "content": "When provided as part of the user documentation, the controls provided in Table A.1 should be taken \ninto account.\nB.6.2.8  AI system recording of event logs\n\nControl\n\nThe organization should determine at which phases of the AI system life cycle, record keeping of event \nImplementation guidance\nlogs should be enabled, but at the minimum when the AI system is in use.\n\nThe organization should ensure logging for AI systems it deploys to automatically collect and record \nevent  logs  related  to  certain  events  that  occur  during  operation.  Such  logging  can  include  but  is  not \nlimited to:\n\n—  traceability of the AI system’s functionality to ensure that the AI system is operating as intended;\n\n—  detection of the AI system’s performance outside of the AI system’s intended operating conditions \nthat can result in undesirable performance on production data or impacts to relevant interested \nparties through monitoring of the operation of the AI system."
  },
  {
    "chunk_id": "chunk_154",
    "content": "AI system event logs can include information, such as the time and date each time the AI system is used, \nthe production data on which the AI system operates on, the outputs that fall out of the range of the \nintended operation of the AI system, etc.\n\nEvent logs should be kept for as long as required for the intended use of the AI system and within the \ndata retention policies of the organization. Legal requirements related to data retention can apply.\n\n36\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nOther information\n\nSome AI systems, such as biometric identification systems, can have additional logging requirements \ndepending on jurisdiction. Organizations should be aware of these requirements.\nB.7  Data for AI systems\n\nB.7.1  Objective"
  },
  {
    "chunk_id": "chunk_155",
    "content": "B.7.1  Objective\n\nTo ensure that the organization understands the role and impacts of data in AI systems in the application \nand development, provision or use of AI systems throughout their life cycles.\nB.7.2  Data for development and enhancement of AI system\n\nControl\n\nThe organization should define, document and implement data management processes related to the \nImplementation guidance\ndevelopment of AI systems.\n\nData management can include various topics such as, but not limited to:\n\n—  privacy and security implications due to the use of data, some of which can be sensitive in nature;\n\n—  security and safety threats that can arise from data dependent AI system development;\n\n—  transparency and explainability aspects including data provenance and the ability to provide an \nexplanation  of  how  data  are  used  for  determining  an  AI  system’s  output  if  the  system  requires \ntransparency and explainability;"
  },
  {
    "chunk_id": "chunk_156",
    "content": "—  representativeness of training data compared to operational domain of use;\n\n—  accuracy and integrity of the data.\n\nNOTE \nISO/IEC 22989.\nB.7.3  Acquisition of data\n\nDetailed  information  of  AI  system  life  cycle  and  data  management  concepts  is  provided  by \n\nControl\n\nThe  organization  should  determine  and  document  details  about  the  acquisition  and  selection  of  the \nImplementation guidance\ndata used in AI systems.\n\nThe organization can need different categories of data from different sources depending on the scope \nand use of their AI systems. Details for data acquisition can include:\n\n—  categories of data needed for the AI system;\n\n—  quantity of data needed;\n\n—  data sources (e.g. internal, purchased, shared, open data, synthetic);\n\n—  characteristics of the data source (e.g. static, streamed, gathered, machine generated);\n\n—  data subject demographics and characteristics (e.g. known or potential biases or other systematic \n\nerrors);"
  },
  {
    "chunk_id": "chunk_157",
    "content": "—  data subject demographics and characteristics (e.g. known or potential biases or other systematic \n\nerrors);\n\n—  prior handling of the data (e.g. previous uses, conformity with privacy and security requirements);\n37\n\n© ISO/IEC 2023 – All rights reserved \n\n \n \n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\n—  data rights (e.g. PII, copyright);\n\n—  associated meta data (e.g. details of data labelling and enhancing);\n\nOther information\n—  provenance of the data.\n\nThe data categories and a structure for the data use in ISO/IEC 19944-1 can be used to document details \nabout data acquisition and use.\nB.7.4  Quality of data for AI systems\n\nControl"
  },
  {
    "chunk_id": "chunk_158",
    "content": "The data categories and a structure for the data use in ISO/IEC 19944-1 can be used to document details \nabout data acquisition and use.\nB.7.4  Quality of data for AI systems\n\nControl\n\nThe organization should define and document requirements for data quality and ensure that data used \nImplementation guidance\nto develop and operate the AI system meet those requirements."
  },
  {
    "chunk_id": "chunk_159",
    "content": "The  quality  of  data  used  to  develop  and  operate  AI  systems  potentially  has  significant  impacts  on \nthe  validity  of  the  system’s  outputs.  ISO/IEC  25024  defines  data  quality  as  the  degree  to  which  the \ncharacteristics  of  data  satisfy  stated  and  implied  needs  when  used  under  specified  conditions.  For \nAI systems that use supervised or semi-supervised machine learning, it is important that the quality \nof  training,  validation,  test  and  production  data  are  defined,  measured  and  improved  to  the  extent \npossible, and the organization should ensure that the data are suitable for its intended purpose. The \norganization should consider the impact of bias on system performance and system fairness and make \nsuch adjustments as necessary to the model and data used to improve performance and fairness so they \nOther information\nare acceptable for the use case."
  },
  {
    "chunk_id": "chunk_160",
    "content": "on data quality \nAdditional information regarding data quality is available in the ISO/IEC 5259 series\nfor  analytics  and  ML.  Additional  information  regarding  different  forms  of  bias  in  data  used  in  AI \nsystems is available in ISO/IEC TR 24027.\nB.7.5  Data provenance\n\n2)\n\nControl\n\nThe organization should define and document a process for recording the provenance of data used in its \nImplementation guidance\nAI systems over the life cycles of the data and the AI system."
  },
  {
    "chunk_id": "chunk_161",
    "content": "The organization should define and document a process for recording the provenance of data used in its \nImplementation guidance\nAI systems over the life cycles of the data and the AI system.\n\nAccording  to  ISO  8000-2,  a  record  of  data  provenance  can  include  information  about  the  creation, \nupdate,  transcription,  abstraction,  validation  and  transferring  of  the  control  of  data.  Additionally, \ndata  sharing  (without  transfer  of  control)  and  data  transformations  can  be  considered  under  data \nprovenance. Depending on factors such as the source of the data, its content and the context of its use, \norganizations should consider whether measures to verify the provenance of the data are needed.\nB.7.6  Data preparation\n\nControl\n\nThe  organization  shall  define  and  document  its  criteria  for  selecting  data  preparations  and  the  data \nImplementation guidance\npreparation methods to be used."
  },
  {
    "chunk_id": "chunk_162",
    "content": "Control\n\nThe  organization  shall  define  and  document  its  criteria  for  selecting  data  preparations  and  the  data \nImplementation guidance\npreparation methods to be used.\n\nData  used  in  an  AI  system  ordinarily  needs  preparation  to  make  it  usable  for  a  given  AI  task.  For \nexample, machine learning algorithms are sometimes intolerant of missing or incorrect entries, non-\n38\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nnormal  distribution  and  widely  varying  scales.  Preparation  methods  and  transforms  can  be  used  to \nincrease the quality of the data. Failure to properly prepare the data can potentially lead to AI system \nerrors. Common preparation methods and transformations for data used in AI systems include:"
  },
  {
    "chunk_id": "chunk_163",
    "content": "—  statistical  exploration  of  the  data  (e.g.  distribution,  mean,  median,  standard  deviation,  range, \nstratification,  sampling)  and  statistical  metadata  (e.g.  data  documentation  initiative  (DDI) \nspecification\n\n[28]\n\n);\n\n—  cleaning (i.e. correcting entries, dealing with missing entries);\n\n— \n\nimputation (i.e. methods for filling in missing entries);\n\n—  normalization;\n\n—  scaling;\n\n— \n\nlabelling of the target variables;\n\n—  encoding (e.g. converting categorical variables to numbers).\n\nFor a given AI task, the organization should document its criteria for selecting specific data preparation \nmethods and transforms as well as the specific methods and transforms used in the AI task.\n\nFor  additional  information  on  data  preparation  specific  to  machine  learning  see  the  ISO/IEC  5259 \n\n2)\n\nNOTE \nseries\nB.8  Information for interested parties\n\n and ISO/IEC 23053.\n\nB.8.1  Objective"
  },
  {
    "chunk_id": "chunk_164",
    "content": "2)\n\nNOTE \nseries\nB.8  Information for interested parties\n\n and ISO/IEC 23053.\n\nB.8.1  Objective\n\nTo ensure that relevant interested parties have the necessary information to understand and assess the \nrisks and their impacts (both positive and negative).\nB.8.2  System documentation and information for users\n\nControl\n\nImplementation guidance\nThe organization should determine and provide the necessary information to users of the system.\n\nInformation about the AI system can include both technical details and instructions, as well as general \nnotifications to users that they are interacting with an AI system, depending on the context. This can \nalso include the system itself, as well  as potential  outputs of the system (e.g. notifying users that  an \nimage is created by AI)."
  },
  {
    "chunk_id": "chunk_165",
    "content": "Although  AI  systems  can  be  complex,  it  is  critical  that  users  are  able  to  understand  when  they  are \ninteracting  with  an  AI  system,  how  the  system  works.  Users  also  need  to  understand  its  intended \npurpose and intended uses, its potential to cause harm or benefit the user. Some system documentation \ncan necessarily be targeted for more technical uses (e.g. system administrators), and the organization \nshould understand the needs of different interested parties and what understandability can mean to \nthem. The information should also be accessible, both in terms of ease of use in finding it, as well as for \nusers who can need additional accessibility features.\n\nInformation that can be provided to users include, but are not limited to:\n\n—  purpose of the system;\n\n—  that the user is interacting with an AI system;\n\n—  how to interact with the system;\n\n© ISO/IEC 2023 – All rights reserved \n\n39\n\n \n \n\fISO/IEC 42001:2023(E)"
  },
  {
    "chunk_id": "chunk_166",
    "content": "—  purpose of the system;\n\n—  that the user is interacting with an AI system;\n\n—  how to interact with the system;\n\n© ISO/IEC 2023 – All rights reserved \n\n39\n\n \n \n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\n—  how and when to override the system;\n\n—  technical requirements for system operation, including the computational resources needed, and \n\nlimitations of the system as well as its expected lifetime;\n\n—  needs for human oversight;\n\n— \n\ninformation about accuracy and performance;\n\n—  relevant  information  from  the  impact  assessment,  including  potential  benefits  and  harms, \nparticularly if they are applicable in specific contexts or certain demographic groups (see B.5.2 and \nB.5.4);\n\n—  revisions to claims about the system’s benefits;"
  },
  {
    "chunk_id": "chunk_167",
    "content": "—  revisions to claims about the system’s benefits;\n\n—  updates and changes in how the system works, as well as any necessary maintenance measures, \n\nincluding their frequency;\n\n—  contact information;\n\n—  educational materials for system use.\n\nCriteria used by the organization to determine whether and what information is to be provided should \nbe  documented.  Relevant  criteria  include  but  are  not  limited  to  the  intended  use  and  reasonably \nforeseeable misuse of the AI system, the expertise of the user and specific impact of the AI system."
  },
  {
    "chunk_id": "chunk_168",
    "content": "Information can be provided to users in numerous ways, including documented instructions for use, \nalerts  and  other  notifications  built  into  the  system  itself,  information  on  a  web  page,  etc.  Depending \non which methods the organization uses to provide information, it should validate that the users have \naccess to this information, and that the information provided is complete, up to date and accurate.\nB.8.3  External reporting\n\nControl\n\nThe  organization  should  provide  capabilities  for  interested  parties  to  report  adverse  impacts  of  the \nImplementation guidance\nsystem.\n\nWhile  the  system  operation  should  be  monitored  for  reported  issues  and  failures,  the  organization \nshould  also  provide  capabilities  for  users  or  other  external  parties  to  report  adverse  impacts  (e.g. \nunfairness).\nB.8.4  Communication of incidents\n\nControl"
  },
  {
    "chunk_id": "chunk_169",
    "content": "Control\n\nThe organization should determine and document a plan for communicating incidents to users of the \nImplementation guidance\nsystem.\n\nIncidents  related  to  the  AI  system  can  be  specific  to  the  AI  system  itself,  or  related  to  information \nsecurity  or  privacy  (e.g.  a  data  breach).  The  organization  should  understand  its  obligations  around \nnotifying  users  and  other  interested  party  about  incidents,  depending  on  the  context  in  which  the \nsystem operates. For example, an incident with an AI component that is part of a product that affects \nsafety  can  have  different  notification  requirements  than  other  types  of  systems.  Legal  requirements \n(such as contracts) and regulatory activity can apply, which can specify requirements for:\n\n—  types of incidents that must be communicated;\n\n40\n\n© ISO/IEC 2023 – All rights reserved"
  },
  {
    "chunk_id": "chunk_170",
    "content": "—  types of incidents that must be communicated;\n\n40\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\n—  the timeline for notification;\n\n—  whether and which authorities must be notified;\n\n—  the details required to be communicated.\n\nThe  organization  can  integrate  incident  response  and  reporting  activities  for  AI  into  their  broader \norganizational  incident  management  activities,  but  should  be  aware  of  unique  requirements  related \nto AI systems, or individual components of AI systems (e.g. a PII data breach in training data for the \nOther information\nsystem can have different reporting requirements related to privacy)."
  },
  {
    "chunk_id": "chunk_171",
    "content": "ISO/IEC 27001 and ISO/IEC 27701 provide additional details on incident management for security and \nprivacy respectively.\nB.8.5  Information for interested parties\n\nControl\n\nThe organization should determine and document its obligations to reporting information about the AI \nImplementation guidance\nsystem to interested parties.\n\nIn some cases, a jurisdiction can require information about the system to be shared with authorities \nsuch as regulators. Information can be reported to interested parties such as customers or regulatory \nauthorities within the appropriate timeframe. The information shared can include, for example:\n\n—  technical system documentation, including, but not limited, to data sets for training, validation and \n\ntesting as well as algorithmic choices justifications and verification and validation records;\n\n—  risks related to the system;\n\n—  results of impact assessments;\n\n— \n\nlogs and other system records."
  },
  {
    "chunk_id": "chunk_172",
    "content": "testing as well as algorithmic choices justifications and verification and validation records;\n\n—  risks related to the system;\n\n—  results of impact assessments;\n\n— \n\nlogs and other system records.\n\nThe organization should understand their obligations in this respect and ensure that the appropriate \ninformation is shared with the correct authorities. Additionally, it is presupposed that the organization \nis aware of jurisdictional requirements related to information shared with law enforcement authorities.\nB.9  Use of AI systems\n\nB.9.1  Objective\n\nTo ensure that the organization uses AI systems responsibly and per organizational policies.\nB.9.2  Processes for responsible use of AI systems\n\nControl\n\nImplementation guidance\nThe organization should define and document the processes for the responsible use of AI systems."
  },
  {
    "chunk_id": "chunk_173",
    "content": "Control\n\nImplementation guidance\nThe organization should define and document the processes for the responsible use of AI systems.\n\nDepending on its context, the organization can have many considerations for determining whether to \nuse a particular AI system. Whether the AI system is developed by the organization itself or sourced \nfrom  a  third  party,  the  organization  should  be  clear  on  what  these  considerations  are  and  develop \npolicies to address them. Some examples are:\n\n—  required approvals;\n\n© ISO/IEC 2023 – All rights reserved \n\n41\n\n \n \n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\n—  cost (including for ongoing monitoring and maintenance);\n\n—  approved sourcing requirements;\n\n— \n\nlegal requirements applicable to the organization."
  },
  {
    "chunk_id": "chunk_174",
    "content": "—  cost (including for ongoing monitoring and maintenance);\n\n—  approved sourcing requirements;\n\n— \n\nlegal requirements applicable to the organization.\n\nWhere the organization has accepted policies for the use of other systems, assets, etc., these policies \ncan be incorporated if desired.\nB.9.3  Objectives for responsible use of AI system\n\nControl\n\nImplementation guidance\nThe organization should identify and document objectives to guide the responsible use of AI systems.\n\nThe  organization  operating  in  different  contexts  can  have  different  expectations  and  objectives  for \nwhat constitutes the responsible development of AI systems. Depending on its context, the organization \nshould identify its objectives related to responsible use. Some objectives include:\n\n— \n\nfairness;\n\n—  accountability;\n\n—  transparency;\n\n—  explainability;\n\n—  reliability;\n\n—  safety;\n\n—  robustness and redundancy;\n\n—  privacy and security;\n\n—  accessibility."
  },
  {
    "chunk_id": "chunk_175",
    "content": "— \n\nfairness;\n\n—  accountability;\n\n—  transparency;\n\n—  explainability;\n\n—  reliability;\n\n—  safety;\n\n—  robustness and redundancy;\n\n—  privacy and security;\n\n—  accessibility.\n\nOnce  defined,  the  organization  should  implement  mechanisms  to  achieve  its  objectives  within  the \norganization. This can include determining if a third-party solution fulfils the organization’s objectives \nor  if  an  internally  developed  solution  is  applicable  for  the  intended  use.  The  organization  should \ndetermine at which stages of the AI system life cycle meaningful human oversight objectives should be \nincorporated. This can include:\n\n— \n\ninvolving  human  reviewers  to  check  the  outputs  of  the  AI  system,  including  having  authority  to \noverride decisions made by the AI system;"
  },
  {
    "chunk_id": "chunk_176",
    "content": "— \n\ninvolving  human  reviewers  to  check  the  outputs  of  the  AI  system,  including  having  authority  to \noverride decisions made by the AI system;\n\n—  ensuring that human oversight is included if required for acceptable use of the AI system according \nto instructions or other documentation associated with the intended deployment of the AI system;\n\n—  monitoring the performance of the AI system, including the accuracy of the AI system outputs;\n\n—  reporting concerns related to the outputs of the AI system and their impact to relevant interested \n\nparties;\n\n—  reporting concerns with changes in the performance or ability of the AI system to make correct \n\noutputs on the production data;\n\n—  considering whether automated decision-making is appropriate for a responsible approach to the \n\nuse of an AI system and the intended use of the AI system."
  },
  {
    "chunk_id": "chunk_177",
    "content": "outputs on the production data;\n\n—  considering whether automated decision-making is appropriate for a responsible approach to the \n\nuse of an AI system and the intended use of the AI system.\n\nThe  need  for  human  oversight  can  be  informed  by  the  AI  system  impact  assessments  (see  B.5).  The \npersonnel involved in human oversight activities related to the AI system should be informed of, trained \n42\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nand understand the instructions and other documentation to the AI system and the duties they carry \nout to satisfy human oversight objectives. When reporting performance issues, human oversight can \nOther information\naugment automated monitoring."
  },
  {
    "chunk_id": "chunk_178",
    "content": "Annex  C  provides  examples  of  organizational  objectives  for  managing  risk,  which  can  be  useful  in \ndetermining the objectives for AI system use.\nB.9.4  Intended use of the AI system\n\nControl\n\nThe  organization  should  ensure  that  the  AI  system  is  used  according  to  the  intended  uses  of  the  AI \nImplementation guidance\nsystem and its accompanying documentation.\n\nThe AI system should be deployed according to the instructions and other documentation associated \nwith  the  AI  system  (see  B.8.2).  The  deployment  can  require  specific  resources  to  support  the \ndeployment, including the need to ensure that human oversight is applied as required (see B.9.3). It can \nbe necessary that for acceptable use of the AI system, the data that the AI system is used on aligns with \nthe documentation associated with the AI system to ensure that the AI system performance is accurate."
  },
  {
    "chunk_id": "chunk_179",
    "content": "The  operation  of  the  AI  system  should  be  monitored  (see  B.6.2.6).  Where  the  correct  deployment  of \nthe AI system according to its associated instructions causes concern regarding the impact to relevant \ninterested parties or the organization’s legal requirements, the organization should communicate its \nconcerns to the relevant personnel inside the organization as well as to any third-party suppliers of the \nAI system."
  },
  {
    "chunk_id": "chunk_180",
    "content": "The  organization  should  keep  event  logs  or  other  documentation  related  to  the  deployment  and \noperation  of  the  AI  system  which  can  be  used  to  demonstrate  that  the  AI  system  is  being  used  as \nintended or to help with communicating concerns related to the intended use of the AI system. The time \nperiod during which event logs and other documentation are kept depends on the intended use of the \nAI system, the organization’s data retention policies and relevant legal requirements for data retention.\nB.10 Third-party and customer relationships\n\nB.10.1 Objective\n\nTo ensure that the organization understands its responsibilities and remains accountable, and risks are \nappropriately apportioned when third parties are involved at any stage of the AI system life cycle.\nB.10.2 Allocating responsibilities\n\nControl"
  },
  {
    "chunk_id": "chunk_181",
    "content": "Control\n\nThe  organization  should  ensure  that  responsibilities  within  their  AI  system  life  cycle  are  allocated \nImplementation guidance\nbetween the organization, its partners, suppliers, customers and third parties.\n\nIn an AI system life cycle, responsibilities can be split between parties providing data, parties providing \nalgorithms and models, parties developing or using the AI system and being accountable with regard \nto some or all interested parties. The organization should document all parties intervening in the AI \nsystem life cycle and their roles and determine their responsibilities.\n\nWhere the organization supplies an AI system to a third party, the organization should ensure that it \ntakes a responsible approach to developing the AI system. See the controls and guidance in B.6. The \norganization should be able to provide the necessary documentation (see B.6.2.7 and B.8.2) for the AI \n43\n\n© ISO/IEC 2023 – All rights reserved \n\n \n \n\fISO/IEC 42001:2023(E)"
  },
  {
    "chunk_id": "chunk_182",
    "content": "© ISO/IEC 2023 – All rights reserved \n\n \n \n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nsystem to relevant interested parties and to the third party that the organization is supplying the AI \nsystem to."
  },
  {
    "chunk_id": "chunk_183",
    "content": "system to relevant interested parties and to the third party that the organization is supplying the AI \nsystem to.\n\nWhen  processed  data  includes  PII,  responsibilities  are  usually  split  between  PII  processors  and \ncontrollers.  ISO/IEC  29100  provides  further  information  on  PII  controllers  and  PII  processors. \nWhere the privacy of PII is to be preserved, controls such as those described in ISO/IEC 27701 should \nbe  considered.  Based  on  the  organization’s  and  AI  system’s  data  processing  activities  on  PII  and \nthe  organization’s  role  in  application  and  development  of  the  AI  system  through  their  life  cycle,  the \norganization can take on the role of a PII controller (or joint PII controller), PII processor or both.\nB.10.3 Suppliers\n\nControl"
  },
  {
    "chunk_id": "chunk_184",
    "content": "Control\n\nThe organization should establish a process to ensure that its usage of services, products or materials \nprovided by suppliers aligns with the organization’s approach to the responsible development and use \nImplementation guidance\nof AI systems.\n\nOrganizations developing or using an AI system can utilize suppliers in a number of ways, from sourcing \ndatasets, machine learning algorithms or models, or other components of a system such as software \nlibraries, to an entire AI system itself for use on its own or as part of another product (e.g. a vehicle).\n\nOrganizations should consider different types of suppliers, what they supply, and the varying level of \nrisk this can pose to the system and organization as a whole in determining the selection of suppliers, \nthe requirements placed on those suppliers, and the levels of ongoing monitoring and evaluation needed \nfor the suppliers."
  },
  {
    "chunk_id": "chunk_185",
    "content": "Organizations should document how the AI system and AI system components are integrated into AI \nsystems developed or used by the organization.\n\nWhere  the  organization  considers  that  the  AI  system  or  AI  system  components  from  a  supplier  do \nnot perform as intended or can result in impacts to individuals or groups of individuals, or both, and \nsocieties that are not aligned with the responsible approach to AI systems taken by the organization, \nthe organization should require the supplier to take corrective actions. The organization can decide to \nwork with the supplier to achieve this objective.\n\nThe  organization  should  ensure  that  the  supplier  of  an  AI  system  delivers  appropriate  and  adequate \ndocumentation related to the AI system (see B.6.2.7 and B.8.2).\nB.10.4 Customers\n\nControl"
  },
  {
    "chunk_id": "chunk_186",
    "content": "Control\n\nThe organization should ensure that its responsible approach to the development and use of AI systems \nImplementation guidance\nconsiders their customer expectations and needs.\n\nThe organization should understand customer expectations and needs when it is supplying a product \nor  service  related  to  an  AI  system  (i.e.  when  it  is  itself  a  supplier).  These  can  come  in  the  form  of \nrequirements for the product or service itself during a design or engineering phase, or in the form of \ncontractual  requirements  or  general  usage  agreements.  One  organization  can  have  many  different \ntypes of customer relationships, and these can all have different needs and expectations.\n\nThe  organization  should  particularly  understand  the  complex  nature  of  supplier  and  customer \nrelationships and understand where responsibility lies with the provider of the AI system and where it \nlies with the customer, while still meeting needs and expectations.\n\n44"
  },
  {
    "chunk_id": "chunk_187",
    "content": "44\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nFor example, the organization can identify risks related to the use of its AI products and services by the \ncustomer and can decide to treat the identified risks by giving appropriate information to its customer, \nso that the customer can then treat the corresponding risks.\n\nAs an example of appropriate information, when an AI system is valid for a certain domain of use, the \nlimits of the domain should be communicated to the customer. See B.6.2.7 and B.8.2.\n\n© ISO/IEC 2023 – All rights reserved \n\n45\n\n \n \n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited."
  },
  {
    "chunk_id": "chunk_188",
    "content": "Licensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nAnnex C \n\n(informative) \nPotential AI-related organizational objectives and risk sources\n\nC.1  General\n\nThis  annex  outlines  potential  organizational  objectives,  risk  sources  and  descriptions  that  can  be \nconsidered by the organization when managing risks. This annex is not intended to be exhaustive or \napplicable for every organization. The organization should determine the objectives and risk sources \nthat  are  relevant.  ISO/IEC  23894  provides  more  detailed  information  on  these  objectives  and  risk \nsources,  and  their  relationship  to  risk  management.  Evaluation  of  AI  systems,  initially,  regularly \nand  when  warranted,  provides  evidence  that  an  AI  system  is  being  assessed  against  organizational \nobjectives.\nC.2  Objectives\n\nC.2.1  Accountability"
  },
  {
    "chunk_id": "chunk_189",
    "content": "C.2.1  Accountability\n\nThe use of AI can change existing accountability frameworks. Where previously persons would be held \naccountable for their actions, their actions can now be supported by or based on the use of an AI system.\nC.2.2  AI expertise\n\nA  selection  of  dedicated  specialists  with  interdisciplinary  skill  sets  and  expertise  in  assessing, \ndeveloping and deploying AI systems is needed.\nC.2.3  Availability and quality of training and test data\n\nAI systems based on ML need training, validation and test data in order to train and verify the systems \nfor the intended behaviour.\nC.2.4  Environmental impact\n\nThe use of AI can have positive and negative impacts on the environment.\nC.2.5  Fairness\n\nThe inappropriate application of AI systems for automated decision-making can be unfair to specific \npersons or groups of persons.\nC.2.6  Maintainability"
  },
  {
    "chunk_id": "chunk_190",
    "content": "The inappropriate application of AI systems for automated decision-making can be unfair to specific \npersons or groups of persons.\nC.2.6  Maintainability\n\nMaintainability is related to the ability of the organization to handle modifications of the AI system in \norder to correct defects or adjust to new requirements.\nC.2.7  Privacy\n\nThe misuse or disclosure of personal and sensitive data (e.g. health records) can have harmful effects \non data subjects.\n\n46\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nC.2.8  Robustness\n\nIn  AI,  robustness  properties  demonstrate  the  ability  (or  inability)  of  the  system  to  have  comparable \nperformance on new data as on the data on which it was trained or the data of typical operations.\nC.2.9  Safety"
  },
  {
    "chunk_id": "chunk_191",
    "content": "Safety  relates  to  the  expectation  that  a  system  does  not,  under  defined  conditions,  lead  to  a  state  in \nwhich human life, health, property or the environment is endangered.\nC.2.10 Security\n\nIn the context of AI and in particular with regard to AI systems based on ML approaches, new security \nissues should be considered beyond classical information and system security concerns.\nC.2.11 Transparency and explainability\n\nTransparency  relates  both  to  characteristics  of  an  organization  operating  AI  systems  and  to  those \nsystems  themselves.  Explainability  relates  to  explanations  of  important  factors  influencing  the  AI \nsystem results that are provided to interested parties in a way understandable to humans.\nC.3  Risk sources\n\nC.3.1  Complexity of environment"
  },
  {
    "chunk_id": "chunk_192",
    "content": "C.3.1  Complexity of environment\n\nWhen AI systems operate in complex environments, where the range of situation is broad, there can be \nuncertainty on the performance and therefore a source of risk (e.g. complex environment of autonomous \ndriving).\nC.3.2  Lack of transparency and explainability\n\nThe  inability  to  provide  appropriate  information  to  interested  parties  can  be  a  source  of  risk  (i.e.  in \nterms of trustworthiness and accountability of the organization).\nC.3.3  Level of automation\n\nThe  level  of  automation  can  have  an  impact  on  various  areas  of  concerns,  such  as  safety,  fairness  or \nsecurity.\nC.3.4  Risk sources related to machine learning\n\nThe quality of data used for ML and the process used to collect data can be sources of risk, as they can \nimpact objectives such as safety and robustness (e.g. due to issues in data quality or data poisoning).\nC.3.5  System hardware issues"
  },
  {
    "chunk_id": "chunk_193",
    "content": "Risk  sources  related  to  hardware  include  hardware  errors  based  on  defective  components  or \ntransferring trained ML models between different systems.\nC.3.6  System life cycle issues\n\nSources  of  risk  can  appear  over  the  entire  AI  system  life  cycle  (e.g.  flaws  in  design,  inadequate \ndeployment, lack of maintenance, issues with decommissioning).\n\n© ISO/IEC 2023 – All rights reserved \n\n47\n\n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nC.3.7  Technology readiness\n\nRisk sources can be related to less mature technology due to unknown factors (e.g. system limitations \nand  boundary  conditions,  performance  drift),  but  also  due  to  the  more  mature  technology  due  to \ntechnology complacency.\n\n48\n\n© ISO/IEC 2023 – All rights reserved"
  },
  {
    "chunk_id": "chunk_194",
    "content": "48\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nAnnex D \n\n(informative) \nUse of the AI management system across domains or sectors\n\nD.1  General\n\nThis management system is applicable to any organization developing, providing or using products or \nservices that utilize an AI system. Therefore, it is applicable potentially to a great variety of products \nand  services,  in  different  sectors,  which  are  subject  to  obligations,  good  practices,  expectations  or \ncontractual commitment towards interested parties. Examples of sectors are:\n\n—  health;\n\n—  defence;\n\n—  transport;\n\n— \n\nfinance;\n\n—  employment;\n\n—  energy."
  },
  {
    "chunk_id": "chunk_195",
    "content": "—  health;\n\n—  defence;\n\n—  transport;\n\n— \n\nfinance;\n\n—  employment;\n\n—  energy.\n\nVarious  organizational  objectives  (see  Annex  C  for  possible  objectives)  can  be  considered  for  the \nresponsible development and use of an AI system. This document provides requirements and guidance \nfrom an AI technology specific view. For several of the potential objectives, generic or sector-specific \nmanagement  system  standards  exist.  These  management  system  standards  consider  the  objective \nusually  from  a  technology  neutral  point  of  view,  while  the  AI  management  system  provides  AI \ntechnology specific considerations."
  },
  {
    "chunk_id": "chunk_196",
    "content": "AI systems consist not only of components using AI technology, but can use a variety of technologies \nand  components.  Responsible  development  and  use  of  an  AI  system  therefore  requires  taking  into \naccount  not  only  AI-specific  considerations,  but  also  the  system  as  a  whole  with  all  the  technologies \nand  components  that  are  used.  Even  for  the  AI  technology  specific  part,  other  aspects  besides  AI-\nspecific considerations should be taken into account. For example, as AI is an information processing \ntechnology,  information  security  applies  generally  to  it.  Objectives  such  as  safety,  security,  privacy \nand  environmental  impact  should  be  managed  holistically  and  not  separately  for  AI  and  the  other \ncomponents  of  the  system.  Integration  of  the  AI  management  system  with  generic  or  sector-specific \nmanagement system standards for relevant topics is therefore essential for responsible development"
  },
  {
    "chunk_id": "chunk_197",
    "content": "management system standards for relevant topics is therefore essential for responsible development \nand use of an AI system.\nD.2  Integration of AI management system with other management system \nstandards"
  },
  {
    "chunk_id": "chunk_198",
    "content": "When  providing  or  using  AI  systems,  the  organization  can  have  objectives  or  obligations  related \nto  aspects  which  are  topics  of  other  management  system  standards.  These  can  include,  for  example, \nsecurity, privacy, quality, respectively topics covered in ISO/IEC 27001, ISO/IEC 27701 and ISO 9001.\n\nWhen  providing,  using  or  developing  AI  systems,  potential  relevant  generic  management  system \nstandards, but not limited to that, are:\n\n—  ISO/IEC  27001:  In  most  contexts,  security  is  key  to  achieving  the  objectives  of  the  organization \nwith the AI system. The way an organization pursues security objectives depends on its context \nand its own policies. If an organization identifies the need to implement an AI management system \n49\n\n© ISO/IEC 2023 – All rights reserved \n\n \n \n \n\fISO/IEC 42001:2023(E)"
  },
  {
    "chunk_id": "chunk_199",
    "content": "© ISO/IEC 2023 – All rights reserved \n\n \n \n \n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nand  to  address  security  objectives  in  a  similar  thorough  and  systematic  way,  it  can  implement \nan  information  security  management  system  in  conformity  with  ISO/IEC  27001.  Given  that  both \nISO/IEC 27001 and the AI management systems use the high-level structure, their integrated use \nis facilitated and of great benefit for the organization. In this case, the way to implement controls \nwhich (partly) relate to information security in this document (see B.6.1.2) can be integrated with \nthe organization’s implementation of ISO/IEC 27001."
  },
  {
    "chunk_id": "chunk_200",
    "content": "—  ISO/IEC 27701: In many context and application domains, PIIs are processed by AI systems. The \norganization can then comply with the applicable obligations for privacy and with its own policies \nand objectives. Similarly, as for ISO/IEC 27001, the organization can benefit from the integration of \nISO/IEC 27701 with the AI management system. Privacy-related objectives and controls of the AI \nmanagement system (see B.2.3 and B.5.4) can be integrated with the organization’s implementation \nof ISO/IEC 27701."
  },
  {
    "chunk_id": "chunk_201",
    "content": "—  ISO  9001:  For  many  organizations,  conformity  to  ISO  9001  is  a  key  sign  that  they  are  customer-\noriented and genuinely concerned about internal effectiveness. Independent conformity assessment \nto ISO 9001 facilitates business across organizations and inspires customer confidence in products or \nservices. The level of customer’s confidence in an organization or AI system can be highly reinforced \nwhen an AI management system is implemented jointly with ISO 9001 when AI technologies are \ninvolved. The AI management system can be complementary to the ISO 9001 requirements (risk \nmanagement, software development, supply chain coherence, etc.) in helping the organization meet \nits objectives."
  },
  {
    "chunk_id": "chunk_202",
    "content": "Besides the generic management system standards mentioned above, an AI management system can \nalso be used jointly with a management system dedicated to a sector. For example, both ISO 22000 and \nan AI management system are relevant for an AI system that is used for food production, preparation \nand  logistics.  Another  example  is  ISO  13485.  The  implementation  of  an  AI  management  system  can \nsupport  requirements  related  to  medical  device  software  in  ISO  13485  or  requirements  from  other \nInternational Standards from the medical sector such as IEC 62304.\n\n50\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nISO/IEC 42001:2023(E)\n\nBibliography\n\nData quality — Part 2: Vocabulary\n\nISO 8000-2, \n\nQuality management systems — Requirements"
  },
  {
    "chunk_id": "chunk_203",
    "content": "ISO/IEC 42001:2023(E)\n\nBibliography\n\nData quality — Part 2: Vocabulary\n\nISO 8000-2, \n\nQuality management systems — Requirements\n\nErgonomics  of  human-system  interaction  —  Part  210:  Human-centred  design  for \n\nISO 9001, \ninteractive systems\nISO  9241-210, \n\nMedical  devices  —  Quality  management  systems  —  Requirements  for  regulatory \n\npurposes\nISO  13485, \n\nFood  safety  management  systems  —  Requirements  for  any  organization  in  the  food \n\nchain\nISO  22000, \n\nMedical device software — Software life cycle processes\n\nIEC 62304, \n\nSafety aspects — Guidelines for their inclusion in standards\n\nInformation  technology  —  Artificial  intelligence  —  Assessment  of  machine \n\nISO/IEC Guide 51, \nlearning classification performance\nISO/IEC  TS  4213, \n\nData quality for analytics and machine learning (ML)\n\nISO/IEC 5259 (all parts\n\n, \n\nInformation technology — Artificial intelligence — AI system life cycle process\n\n2)\n\nISO/IEC 5338, \nand services\nISO/IEC 17065,"
  },
  {
    "chunk_id": "chunk_204",
    "content": "ISO/IEC 5259 (all parts\n\n, \n\nInformation technology — Artificial intelligence — AI system life cycle process\n\n2)\n\nISO/IEC 5338, \nand services\nISO/IEC 17065, \n\nConformity assessment — Requirements for bodies certifying products, processes \n\nCloud computing and distributed platforms ─ Data flow, data categories and data \n\nuse — Part 1: Fundamentals\nISO/IEC 19944-1, \n\nFramework for Artificial Intelligence (AI) Systems Using Machine Learning (ML)\n\n[13] \n\nISO/IEC 23053, \n\nInformation technology — Artificial intelligence — Guidance on risk management\n\nInformation technology — Artificial intelligence (AI) — Bias in AI systems and \n\nISO/IEC 23894, \nAI aided decision making\nISO/IEC TR 24027, \n\nArtificial Intelligence (AI) — Assessment of the robustness of neural networks \n\n— Part 1: Overview\nISO/IEC TR 24029-1, \n\nInformation  technology  —  Artificial  intelligence  —  Overview  of  ethical  and \n\nsocietal concerns\nISO/IEC  TR  24368,"
  },
  {
    "chunk_id": "chunk_205",
    "content": "— Part 1: Overview\nISO/IEC TR 24029-1, \n\nInformation  technology  —  Artificial  intelligence  —  Overview  of  ethical  and \n\nsocietal concerns\nISO/IEC  TR  24368, \n\nSystems and software engineering — Systems and software Quality Requirements \n\nand Evaluation (SQuaRE) — Measurement of data quality\nISO/IEC 25024, \n\nSoftware  engineering  —  Systems  and  software  Quality  Requirements  and \n\nEvaluation (SQuaRE) — Quality model for AI systems\nISO/IEC  25059, \n\nInformation  technology  —  Security  techniques  —  Information  security \n\nmanagement systems — Overview and vocabulary\nISO/IEC  27000:2018, \n\nSecurity techniques — Extension to ISO/IEC 27001 and ISO/IEC 27002 for privacy \n\ninformation management — Requirements and guidelines\nISO/IEC 27701, \n\nInformation security, cybersecurity and privacy protection — Information security \n\nmanagement systems — Requirements\nISO/IEC 27001, \n\nInformation technology — Security techniques — Privacy framework\n\n[23] \n\nISO/IEC 29100,"
  },
  {
    "chunk_id": "chunk_206",
    "content": "management systems — Requirements\nISO/IEC 27001, \n\nInformation technology — Security techniques — Privacy framework\n\n[23] \n\nISO/IEC 29100, \n\n© ISO/IEC 2023 – All rights reserved \n\n51\n\n[1] \n\n[2] \n\n[3] \n\n[4] \n\n[5] \n\n[6] \n\n[7] \n\n[8] \n\n[9] \n\n[10] \n\n[11] \n\n[12] \n\n[14] \n\n[15] \n\n[16] \n\n[17] \n\n[18] \n\n[19] \n\n[20] \n\n[21] \n\n[22] \n\n \n \n\fISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nRisk management — Guidelines\n\n[24] \n\nISO 31000:2018, \n\nWhistleblowing management systems — Guidelines\n\n[25] \n\nISO 37002, \n\nInformation technology — Governance of IT for the organization\n\n[26] \n\n[27] \n\nInformation technology — Governance of IT — Governance implications of the use \n\nISO/IEC 38500:2015, \nof artificial intelligence by organizations\nISO/IEC 38507,"
  },
  {
    "chunk_id": "chunk_207",
    "content": "[26] \n\n[27] \n\nInformation technology — Governance of IT — Governance implications of the use \n\nISO/IEC 38500:2015, \nof artificial intelligence by organizations\nISO/IEC 38507, \n\n[28]  Lifecycle D.D.I. 3.3, 2020-04-15. Data Documentation Initiative (DDI) Alliance. [viewed on 2022-\n\n02-19]. Available at: https:// ddialliance .org/ Specification/ DDI -Lifecycle/ 3 .3/ \n\n[29]  Risk Framework N.I.S.T.-A.I. 1.0, 2023-01-26. National Institute of Technology (NIST) [viewed on \n\n2023-04-17] https:// www .nist .gov/ itl/ ai -risk -management -framework\n\n52\n\n© ISO/IEC 2023 – All rights reserved\n\n \n \n \n \n \n\fLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\n\fISO/IEC 42001:2023(E)"
  },
  {
    "chunk_id": "chunk_208",
    "content": "ISO/IEC 42001:2023(E)\n\nLicensed to Tariq Aldowaisan / Tariq Aldowaisan (tariq@glc-im.com) \nISO Store Order: OP-750234 license #1/ Downloaded: 2024-02-19 \nSingle user licence only, copying and networking prohibited.\n\nICS 03.100.70; 35.020\n\nPrice based on 51 pages\n\n© ISO/IEC 2023 – All rights reserved"
  }
]